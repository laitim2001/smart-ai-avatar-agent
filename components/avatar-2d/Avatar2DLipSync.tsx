'use client'

import { useRef, useEffect, useState } from 'react'
import type { VisemeEvent } from '@/types/viseme'
import { VISEME_TO_MORPH_TARGET, VISEME_INTENSITY } from '@/types/viseme'

interface Avatar2DLipSyncProps {
  /** Avatar åœ–ç‰‡ URL */
  avatarImageUrl: string
  /** éŸ³è¨Š URLï¼ˆBase64 Data URL æˆ– HTTP URLï¼‰ */
  audioUrl?: string
  /** Viseme äº‹ä»¶é™£åˆ— */
  visemes?: VisemeEvent[]
  /** æ˜¯å¦è‡ªå‹•æ’­æ”¾ */
  autoPlay?: boolean
  /** æ’­æ”¾å®Œæˆå›èª¿ */
  onPlaybackComplete?: () => void
  /** å¯¬åº¦ */
  width?: number
  /** é«˜åº¦ */
  height?: number
}

/**
 * 2D Avatar Lip Sync Component
 *
 * ä½¿ç”¨ Canvas 2D å˜´éƒ¨å€åŸŸè®Šå½¢æŠ€è¡“å¯¦ç¾å³æ™‚ Lip Sync
 * æ ¹æ“š Viseme è³‡æ–™å³æ™‚æ“æ§ Avatar åœ–ç‰‡çš„å˜´éƒ¨å€åŸŸ
 */
export default function Avatar2DLipSync({
  avatarImageUrl,
  audioUrl,
  visemes = [],
  autoPlay = false,
  onPlaybackComplete,
  width = 512,
  height = 512
}: Avatar2DLipSyncProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const audioRef = useRef<HTMLAudioElement>(null)
  const imageRef = useRef<HTMLImageElement | null>(null)
  const animationFrameRef = useRef<number | null>(null)

  const [isPlaying, setIsPlaying] = useState(false)
  const [currentViseme, setCurrentViseme] = useState<number>(0)
  const [mouthOpenness, setMouthOpenness] = useState<number>(0)
  const [imageLoaded, setImageLoaded] = useState(false)
  const hasAutoPlayedRef = useRef(false)
  const prevVisemeRef = useRef<number>(0)

  /**
   * ç¹ªè£½å¸¶æœ‰å˜´éƒ¨è®Šå½¢çš„ Avatar ç•«é¢
   * ä½¿ç”¨ Canvas 2D transform å°å˜´éƒ¨å€åŸŸé€²è¡Œå‚ç›´/æ°´å¹³ç¸®æ”¾
   */
  const drawFrame = (
    ctx: CanvasRenderingContext2D,
    img: HTMLImageElement,
    intensity: number,
    morphTarget: string
  ) => {
    const canvas = ctx.canvas

    // æ¸…ç©º Canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height)

    // å¦‚æœæ²’æœ‰è®Šå½¢ï¼Œç›´æ¥ç¹ªè£½å®Œæ•´åœ–ç‰‡
    if (intensity === 0 || !morphTarget) {
      ctx.drawImage(img, 0, 0, canvas.width, canvas.height)
      return
    }

    // å˜´éƒ¨å€åŸŸå®šç¾©ï¼ˆç›¸å°æ–¼åœ–ç‰‡çš„æ¯”ä¾‹ï¼‰
    // èª¿æ•´ç‚ºæ›´ç²¾ç¢ºçš„è‡‰éƒ¨æ¯”ä¾‹
    const mouthRegion = {
      centerX: 0.5,    // å˜´éƒ¨ä¸­å¿ƒ Xï¼ˆåœ–ç‰‡æ­£ä¸­å¤®ï¼‰
      centerY: 0.72,   // å˜´éƒ¨ä¸­å¿ƒ Yï¼ˆè‡‰éƒ¨ä¸‹æ–¹ç´„ 72%ï¼‰
      width: 0.25,     // å˜´éƒ¨å€åŸŸå¯¬åº¦ï¼ˆåœ–ç‰‡å¯¬åº¦çš„ 25%ï¼‰
      height: 0.08     // å˜´éƒ¨å€åŸŸé«˜åº¦ï¼ˆåœ–ç‰‡é«˜åº¦çš„ 8%ï¼‰
    }

    // è¨ˆç®—å˜´éƒ¨å€åŸŸçš„å¯¦éš›åƒç´ ä½ç½®
    const mouthCenterX = canvas.width * mouthRegion.centerX
    const mouthCenterY = canvas.height * mouthRegion.centerY
    const mouthWidth = canvas.width * mouthRegion.width
    const mouthHeight = canvas.height * mouthRegion.height

    // å˜´éƒ¨å€åŸŸçš„èµ·å§‹ä½ç½®
    const mouthLeft = mouthCenterX - mouthWidth / 2
    const mouthTop = mouthCenterY - mouthHeight / 2

    // æ ¹æ“š morphTarget è¨ˆç®—è®Šå½¢åƒæ•¸
    let scaleX = 1
    let scaleY = 1

    switch (morphTarget) {
      case 'mouthOpen':
        // å˜´å·´å¼µé–‹ï¼šå‚ç›´æ‹‰ä¼¸
        scaleY = 1 + intensity * 0.5
        break
      case 'mouthSmile':
        // å¾®ç¬‘ï¼šæ°´å¹³æ‹‰ä¼¸ï¼Œå‚ç›´å£“ç¸®
        scaleX = 1 + intensity * 0.2
        scaleY = 1 - intensity * 0.1
        break
      case 'mouthPucker':
        // å˜Ÿå˜´ï¼šæ°´å¹³å’Œå‚ç›´å£“ç¸®
        scaleX = 1 - intensity * 0.2
        scaleY = 1 - intensity * 0.2
        break
      case 'mouthFunnel':
        // åœ“å˜´ï¼šå‚ç›´æ‹‰ä¼¸
        scaleY = 1 + intensity * 0.3
        scaleX = 1 - intensity * 0.1
        break
      default:
        break
    }

    // è¨ˆç®—è®Šå½¢å¾Œçš„å˜´éƒ¨å€åŸŸå¤§å°
    const scaledWidth = mouthWidth * scaleX
    const scaledHeight = mouthHeight * scaleY

    // å…ˆç¹ªè£½å®Œæ•´çš„ Avatar åœ–ç‰‡
    ctx.drawImage(img, 0, 0, canvas.width, canvas.height)

    // ç„¶å¾Œåœ¨å˜´éƒ¨å€åŸŸä¸Šæ–¹ç¹ªè£½è®Šå½¢å¾Œçš„å˜´éƒ¨
    ctx.save()

    // æ¸…é™¤åŸå§‹å˜´éƒ¨å€åŸŸ
    ctx.clearRect(
      mouthCenterX - scaledWidth / 2,
      mouthCenterY - scaledHeight / 2,
      scaledWidth,
      scaledHeight
    )

    // ç¹ªè£½è®Šå½¢å¾Œçš„å˜´éƒ¨
    ctx.translate(mouthCenterX, mouthCenterY)
    ctx.scale(scaleX, scaleY)
    ctx.translate(-mouthCenterX, -mouthCenterY)

    // å¾åŸåœ–ä¸­æå–å˜´éƒ¨å€åŸŸä¸¦ç¹ªè£½
    const srcLeft = (img.width * mouthRegion.centerX) - (img.width * mouthRegion.width / 2)
    const srcTop = (img.height * mouthRegion.centerY) - (img.height * mouthRegion.height / 2)
    const srcWidth = img.width * mouthRegion.width
    const srcHeight = img.height * mouthRegion.height

    ctx.drawImage(
      img,
      srcLeft, srcTop, srcWidth, srcHeight,
      mouthLeft, mouthTop, mouthWidth, mouthHeight
    )

    ctx.restore()
  }

  // è¼‰å…¥ Avatar åœ–ç‰‡åˆ° Canvas
  useEffect(() => {
    if (!avatarImageUrl || !canvasRef.current) return

    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d')
    if (!ctx) return

    // å»ºç«‹æ–°åœ–ç‰‡ç‰©ä»¶
    const img = new Image()
    img.crossOrigin = 'anonymous'

    img.onload = () => {
      imageRef.current = img
      setImageLoaded(true)
      console.log('[Lip Sync] Avatar åœ–ç‰‡è¼‰å…¥å®Œæˆ')

      // åˆå§‹ç¹ªè£½
      drawFrame(ctx, img, 0, 'mouthOpen')
    }

    img.onerror = (error) => {
      console.error('[Lip Sync] Avatar åœ–ç‰‡è¼‰å…¥å¤±æ•—:', error)
    }

    img.src = avatarImageUrl
  }, [avatarImageUrl, width, height])

  // é‡ç½® autoPlay è¿½è¹¤ç•¶ audioUrl æ”¹è®Šæ™‚
  useEffect(() => {
    hasAutoPlayedRef.current = false
    prevVisemeRef.current = 0
  }, [audioUrl])

  // æ’­æ”¾éŸ³è¨Šå’Œ Viseme å‹•ç•«
  useEffect(() => {
    if (!audioUrl || !audioRef.current || visemes.length === 0 || !canvasRef.current || !imageRef.current) return

    const audio = audioRef.current
    const canvas = canvasRef.current
    const ctx = canvas.getContext('2d')
    const img = imageRef.current

    if (!ctx || !img) return

    const updateViseme = () => {
      const currentTime = audio.currentTime * 1000 // è½‰æ›ç‚ºæ¯«ç§’

      // æ‰¾åˆ°ç•¶å‰æ™‚é–“å°æ‡‰çš„ Viseme
      const activeViseme = visemes.find((v, index) => {
        const nextViseme = visemes[index + 1]
        return currentTime >= v.audioOffsetMs &&
               (!nextViseme || currentTime < nextViseme.audioOffsetMs)
      })

      if (activeViseme) {
        const intensity = VISEME_INTENSITY[activeViseme.visemeId as keyof typeof VISEME_INTENSITY] || 0
        const morphTarget = VISEME_TO_MORPH_TARGET[activeViseme.visemeId as keyof typeof VISEME_TO_MORPH_TARGET] || 'mouthOpen'

        setCurrentViseme(activeViseme.visemeId)
        setMouthOpenness(intensity)

        // å³æ™‚ç¹ªè£½å˜´éƒ¨è®Šå½¢
        drawFrame(ctx, img, intensity, morphTarget)

        // Debug æ—¥èªŒ - åªåœ¨ Viseme ID è®ŠåŒ–æ™‚è¨˜éŒ„
        if (intensity > 0 && activeViseme.visemeId !== prevVisemeRef.current) {
          prevVisemeRef.current = activeViseme.visemeId
          console.log(`[Lip Sync] Viseme Changed: ${activeViseme.visemeId} (${morphTarget}), Intensity: ${(intensity * 100).toFixed(0)}%, Time: ${currentTime.toFixed(0)}ms`)
        }
      }

      if (!audio.paused) {
        animationFrameRef.current = requestAnimationFrame(updateViseme)
      }
    }

    const handlePlay = () => {
      setIsPlaying(true)
      animationFrameRef.current = requestAnimationFrame(updateViseme)
      console.log('[Lip Sync] æ’­æ”¾é–‹å§‹')
    }

    const handlePause = () => {
      setIsPlaying(false)
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      console.log('[Lip Sync] æ’­æ”¾æš«åœ')
    }

    const handleEnded = () => {
      setIsPlaying(false)
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      console.log('[Lip Sync] æ’­æ”¾å®Œæˆ')
      onPlaybackComplete?.()
    }

    audio.addEventListener('play', handlePlay)
    audio.addEventListener('pause', handlePause)
    audio.addEventListener('ended', handleEnded)

    // åªåœ¨ autoPlay ç‚º true ä¸”å°šæœªè‡ªå‹•æ’­æ”¾éæ™‚åŸ·è¡Œ
    if (autoPlay && !hasAutoPlayedRef.current && audio.paused && audio.currentTime === 0) {
      hasAutoPlayedRef.current = true
      audio.play().catch(console.error)
    }

    return () => {
      audio.removeEventListener('play', handlePlay)
      audio.removeEventListener('pause', handlePause)
      audio.removeEventListener('ended', handleEnded)
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
    }
  }, [audioUrl, visemes, autoPlay, onPlaybackComplete, imageLoaded])

  const handlePlayPause = () => {
    if (!audioRef.current) return

    if (isPlaying) {
      audioRef.current.pause()
    } else {
      audioRef.current.play().catch(console.error)
    }
  }

  const handleStop = () => {
    if (!audioRef.current || !canvasRef.current || !imageRef.current) return

    audioRef.current.pause()
    audioRef.current.currentTime = 0
    setIsPlaying(false)
    setCurrentViseme(0)
    setMouthOpenness(0)

    // é‡ç½®ç‚ºåˆå§‹ç‹€æ…‹ï¼ˆç„¡è®Šå½¢ï¼‰
    const ctx = canvasRef.current.getContext('2d')
    if (ctx && imageRef.current) {
      drawFrame(ctx, imageRef.current, 0, 'mouthOpen')
    }

    console.log('[Lip Sync] åœæ­¢æ’­æ”¾')
  }

  const handleReplay = () => {
    if (!audioRef.current) return
    audioRef.current.currentTime = 0
    audioRef.current.play().catch(console.error)
  }

  return (
    <div className="relative" style={{ width, height }}>
      {/* Avatar Canvasï¼ˆå¸¶ Lip Sync æ•ˆæœï¼‰ */}
      <div className="relative w-full h-full overflow-hidden rounded-lg bg-gray-100">
        <canvas
          ref={canvasRef}
          width={width}
          height={height}
          className="w-full h-full object-cover"
          style={{
            display: imageLoaded ? 'block' : 'none'
          }}
        />

        {/* Loading ç‹€æ…‹ */}
        {!imageLoaded && (
          <div className="absolute inset-0 flex items-center justify-center">
            <div className="text-center">
              <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-600 mx-auto mb-2" />
              <p className="text-sm text-gray-600">è¼‰å…¥ Avatar...</p>
            </div>
          </div>
        )}
      </div>

      {/* éŸ³è¨Šå…ƒç´ ï¼ˆéš±è—ï¼‰ */}
      {audioUrl && (
        <audio
          ref={audioRef}
          src={audioUrl}
          preload="auto"
          loop={false}
        />
      )}

      {/* æ’­æ”¾æ§åˆ¶ */}
      {audioUrl && imageLoaded && (
        <div className="absolute bottom-4 left-1/2 -translate-x-1/2 flex items-center gap-3 bg-black/70 text-white px-4 py-2 rounded-full backdrop-blur-sm">
          <button
            type="button"
            onClick={handlePlayPause}
            className="hover:scale-110 transition-transform text-lg"
            title={isPlaying ? 'æš«åœ' : 'æ’­æ”¾'}
          >
            {isPlaying ? 'â¸ï¸' : 'â–¶ï¸'}
          </button>
          <button
            type="button"
            onClick={handleStop}
            className="hover:scale-110 transition-transform text-lg"
            title="åœæ­¢"
          >
            â¹ï¸
          </button>
          <button
            type="button"
            onClick={handleReplay}
            className="hover:scale-110 transition-transform text-lg"
            title="é‡æ’­"
          >
            ğŸ”„
          </button>
          <div className="h-4 w-px bg-white/30" />
          <span className="text-xs font-mono">
            Viseme: {currentViseme} | {(mouthOpenness * 100).toFixed(0)}%
          </span>
        </div>
      )}
    </div>
  )
}
