# Story 3.5: TTS API 實作（Azure Speech 語音合成）

## Status
Approved

---

## Story

**As a** 開發者,
**I want** 建立 TTS API，將 LLM 回應文字轉換為語音，
**so that** Avatar 可以「說話」。

---

## Acceptance Criteria

1. 建立 `app/api/tts/route.ts` TTS API 路由
2. 接收 POST 請求，body 包含 `text: string`（要轉換的文字）
3. 使用 Azure Speech SDK，呼叫 TTS API：語音 `zh-TW-HsiaoChenNeural`（繁中女聲）、格式 MP3 16kbps Mono
4. 返回音訊檔案（`Content-Type: audio/mpeg`）
5. 錯誤處理：API 失敗返回 500，包含錯誤訊息 JSON
6. 超時設定：5 秒無回應自動中斷
7. 使用 Postman 測試，上傳文字「你好，我是 Avatar」，收到 MP3 音訊檔
8. 音訊在播放器中可正常播放，語音清晰

---

## Tasks / Subtasks

- [ ] **Task 1: 建立 Azure Speech Client 初始化函式** (AC: 3)
  - [ ] 開啟或建立 `lib/azure/speech.ts` 檔案
  - [ ] 實作 Azure Speech 客戶端配置：
    ```typescript
    import * as sdk from 'microsoft-cognitiveservices-speech-sdk';

    /**
     * 建立 Azure Speech 配置
     * 使用環境變數配置 API Key 與 Region
     */
    export function createSpeechConfig() {
      const apiKey = process.env.AZURE_SPEECH_KEY;
      const region = process.env.AZURE_SPEECH_REGION;

      if (!apiKey || !region) {
        throw new Error(
          'Missing Azure Speech credentials. Please set AZURE_SPEECH_KEY and AZURE_SPEECH_REGION in environment variables.'
        );
      }

      return sdk.SpeechConfig.fromSubscription(apiKey, region);
    }

    /**
     * 取得 TTS 語音名稱
     * @default zh-TW-HsiaoChenNeural (繁中女聲)
     */
    export function getVoiceName() {
      return process.env.AZURE_SPEECH_VOICE || 'zh-TW-HsiaoChenNeural';
    }

    /**
     * 取得音訊格式配置
     * @returns MP3, 16kbps, Mono
     */
    export function getAudioFormat() {
      return sdk.AudioOutputFormat.Audio16Khz32KBitRateMonoMp3;
    }
    ```
  - [ ] 加入 JSDoc 註解說明函式用途
  - [ ] 加入錯誤處理（缺少環境變數時拋出錯誤）
  - [ ] 驗證函式可正確建立配置

- [ ] **Task 2: 定義 TTS API 型別** (AC: 2)
  - [ ] 開啟或建立 `types/audio.ts` 檔案
  - [ ] 定義 TTS Request 型別：
    ```typescript
    export interface TTSRequest {
      text: string;              // 要轉換的文字
      voice?: string;            // 可選，語音名稱（預設 zh-TW-HsiaoChenNeural）
      speed?: number;            // 可選，語速（0.5-2.0，預設 1.0）
      pitch?: number;            // 可選，音調（0.5-2.0，預設 1.0）
    }
    ```
  - [ ] 定義 TTS Response 型別：
    ```typescript
    export interface TTSResponse {
      audio: Buffer;             // 音訊檔案 Buffer
      duration: number;          // 音訊長度（秒）
      format: string;            // 音訊格式（'audio/mpeg'）
    }
    ```
  - [ ] 定義 Error Response 型別（與 Chat API 共用）：
    ```typescript
    export interface ErrorResponse {
      error: string;
      code?: string;
      timestamp: string;
    }
    ```
  - [ ] 加入 JSDoc 註解說明每個型別用途
  - [ ] 驗證型別定義完整且正確

- [ ] **Task 3: 實作 TTS API 路由基本結構** (AC: 1, 2)
  - [ ] 建立目錄 `app/api/tts/`（如尚未存在）
  - [ ] 建立 `app/api/tts/route.ts` 檔案
  - [ ] 實作基本路由結構：
    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createSpeechConfig, getVoiceName, getAudioFormat } from '@/lib/azure/speech';
    import { TTSRequest, ErrorResponse } from '@/types/audio';

    export const runtime = 'nodejs'; // TTS 需要 Node.js runtime（Azure Speech SDK 限制）

    /**
     * TTS API - 將文字轉換為語音
     */
    export async function POST(request: NextRequest) {
      try {
        // 解析請求 body
        const body: TTSRequest = await request.json();

        // 驗證必要欄位
        if (!body.text || body.text.trim() === '') {
          return NextResponse.json(
            {
              error: 'Missing required field: text',
              code: 'INVALID_REQUEST',
              timestamp: new Date().toISOString()
            } as ErrorResponse,
            { status: 400 }
          );
        }

        // 驗證文字長度（避免過長）
        if (body.text.length > 1000) {
          return NextResponse.json(
            {
              error: 'Text too long (max 1000 characters)',
              code: 'TEXT_TOO_LONG',
              timestamp: new Date().toISOString()
            } as ErrorResponse,
            { status: 400 }
          );
        }

        // 後續 Task 將實作 TTS 轉換邏輯
        return new NextResponse('TTS conversion to be implemented', {
          status: 200,
          headers: {
            'Content-Type': 'audio/mpeg'
          }
        });

      } catch (error) {
        console.error('[TTS API Error]', error);

        return NextResponse.json(
          {
            error: error instanceof Error ? error.message : 'Internal server error',
            code: 'API_ERROR',
            timestamp: new Date().toISOString()
          } as ErrorResponse,
          { status: 500 }
        );
      }
    }
    ```
  - [ ] 加入 JSDoc 註解說明 API 用途
  - [ ] 設定 Node.js Runtime（Azure Speech SDK 需要）
  - [ ] 實作基本請求驗證（text 欄位檢查、長度限制）
  - [ ] 實作基本錯誤處理
  - [ ] 驗證 API 路由建立成功

- [ ] **Task 4: 實作 Azure Speech TTS 轉換邏輯** (AC: 3)
  - [ ] 在 `route.ts` 中實作 TTS 轉換：
    ```typescript
    import * as sdk from 'microsoft-cognitiveservices-speech-sdk';

    // 建立 Speech 配置
    const speechConfig = createSpeechConfig();
    speechConfig.speechSynthesisVoiceName = body.voice || getVoiceName();
    speechConfig.speechSynthesisOutputFormat = getAudioFormat();

    // 設定語速與音調（如有）
    let ssml = body.text;
    if (body.speed || body.pitch) {
      ssml = `
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-TW">
          <voice name="${speechConfig.speechSynthesisVoiceName}">
            <prosody rate="${body.speed || 1.0}" pitch="${body.pitch || 1.0}">
              ${body.text}
            </prosody>
          </voice>
        </speak>
      `;
    }

    // 建立 TTS 合成器
    const synthesizer = new sdk.SpeechSynthesizer(speechConfig, null);

    // 執行 TTS 轉換（Promise 包裝）
    const audioBuffer = await new Promise<Buffer>((resolve, reject) => {
      const timeoutId = setTimeout(() => {
        synthesizer.close();
        reject(new Error('TTS request timeout (5 seconds exceeded)'));
      }, 5000);

      synthesizer.speakTextAsync(
        body.text,
        (result) => {
          clearTimeout(timeoutId);
          synthesizer.close();

          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            // 轉換成功，取得音訊 Buffer
            const audioData = Buffer.from(result.audioData);
            resolve(audioData);
          } else {
            reject(new Error(`TTS synthesis failed: ${result.errorDetails}`));
          }
        },
        (error) => {
          clearTimeout(timeoutId);
          synthesizer.close();
          reject(error);
        }
      );
    });
    ```
  - [ ] 實作超時控制（5 秒）
  - [ ] 實作 SSML 格式（支援語速、音調調整）
  - [ ] 處理 TTS 結果（成功/失敗）
  - [ ] 驗證音訊 Buffer 正確產生

- [ ] **Task 5: 返回音訊檔案與 Metadata** (AC: 4)
  - [ ] 實作音訊檔案返回邏輯：
    ```typescript
    // 計算音訊長度（估算）
    // MP3 16kbps: ~2KB/秒
    const estimatedDuration = audioBuffer.length / (16 * 1024 / 8);

    // 返回音訊檔案
    return new NextResponse(audioBuffer, {
      status: 200,
      headers: {
        'Content-Type': 'audio/mpeg',
        'Content-Length': audioBuffer.length.toString(),
        'X-Audio-Duration': estimatedDuration.toFixed(2), // 自訂 header（方便客戶端使用）
        'Cache-Control': 'public, max-age=3600' // 快取 1 小時
      }
    });
    ```
  - [ ] 加入 Content-Type header（`audio/mpeg`）
  - [ ] 加入 Content-Length header
  - [ ] 加入自訂 X-Audio-Duration header（音訊長度）
  - [ ] 加入 Cache-Control（快取策略）
  - [ ] 驗證音訊檔案正確返回

- [ ] **Task 6: 實作錯誤分類與處理** (AC: 5, 6)
  - [ ] 實作 TTS 錯誤分類邏輯：
    ```typescript
    catch (error) {
      console.error('[TTS API Error]', error);

      // 分類錯誤類型
      let errorCode = 'API_ERROR';
      let errorMessage = 'Internal server error';
      let statusCode = 500;

      if (error instanceof Error) {
        errorMessage = error.message;

        // Azure Speech API 錯誤
        if (error.message.includes('quota')) {
          errorCode = 'QUOTA_EXCEEDED';
          errorMessage = 'TTS quota exceeded. Please try again later.';
        } else if (error.message.includes('credentials')) {
          errorCode = 'INVALID_CREDENTIALS';
          errorMessage = 'Invalid Azure Speech credentials.';
          statusCode = 401;
        } else if (error.message.includes('timeout')) {
          errorCode = 'TIMEOUT';
          errorMessage = 'TTS request timeout (5 seconds exceeded).';
          statusCode = 408;
        } else if (error.message.includes('synthesis failed')) {
          errorCode = 'SYNTHESIS_FAILED';
          errorMessage = 'Failed to synthesize audio. Please check input text.';
        }
      }

      return NextResponse.json(
        {
          error: errorMessage,
          code: errorCode,
          timestamp: new Date().toISOString()
        } as ErrorResponse,
        { status: statusCode }
      );
    }
    ```
  - [ ] 加入詳細錯誤日誌（console.error）
  - [ ] 測試各種錯誤情境（缺少環境變數、API 失敗、超時）
  - [ ] 驗證錯誤回應格式正確

- [ ] **Task 7: 實作語音參數優化** (AC: 3)
  - [ ] 加入語音參數配置：
    ```typescript
    /**
     * TTS 語音參數配置
     */
    const TTS_CONFIG = {
      // 預設語音
      defaultVoice: 'zh-TW-HsiaoChenNeural',

      // 可選語音列表（未來擴展）
      availableVoices: [
        'zh-TW-HsiaoChenNeural',  // 女聲（預設）
        'zh-TW-YunJheNeural',      // 男聲
        'zh-TW-HsiaoYuNeural'      // 女聲（活潑）
      ],

      // 語速範圍
      speedRange: { min: 0.5, max: 2.0, default: 1.0 },

      // 音調範圍
      pitchRange: { min: 0.5, max: 2.0, default: 1.0 },

      // 音訊格式
      audioFormat: sdk.AudioOutputFormat.Audio16Khz32KBitRateMonoMp3,

      // 超時設定（毫秒）
      timeout: 5000
    };
    ```
  - [ ] 驗證語速、音調參數範圍
  - [ ] 實作參數驗證邏輯（超出範圍返回錯誤）
  - [ ] 測試不同參數組合，確保語音品質
  - [ ] 加入參數說明註解

- [ ] **Task 8: API 測試與驗證** (AC: 7, 8)
  - [ ] 建立測試腳本 `test-tts-api.sh`（開發用）：
    ```bash
    #!/bin/bash
    # 測試 TTS API 使用 curl

    curl -X POST http://localhost:3000/api/tts \
      -H "Content-Type: application/json" \
      -d '{"text": "你好，我是 Avatar"}' \
      --output test-audio.mp3

    echo "Audio saved to test-audio.mp3"
    ```
  - [ ] 使用 Postman 建立 TTS API 測試集合：
    - [ ] 測試 1: 正常文字轉語音（「你好，我是 Avatar」）
    - [ ] 測試 2: 長文字（約 500 字）
    - [ ] 測試 3: 缺少 text 欄位（預期 400 錯誤）
    - [ ] 測試 4: 空 text（預期 400 錯誤）
    - [ ] 測試 5: 超長 text（> 1000 字，預期 400 錯誤）
    - [ ] 測試 6: 自訂語速（speed: 1.5）
    - [ ] 測試 7: 自訂音調（pitch: 1.2）
  - [ ] 執行 `pnpm dev` 啟動開發伺服器
  - [ ] 使用 curl 測試 API，下載音訊檔案
  - [ ] 使用音訊播放器（如 VLC、Windows Media Player）播放測試
  - [ ] 驗證語音清晰、語速適中、發音正確
  - [ ] 使用 Postman 測試所有測試案例
  - [ ] 記錄測試結果於 Dev Agent Record

- [ ] **Task 9: 整合測試與文件** (AC: 1-8)
  - [ ] 建立 `docs/api/tts.md` API 文件：
    ```markdown
    # TTS API 文件

    ## Endpoint
    `POST /api/tts`

    ## Request Body
    \```json
    {
      "text": "你好，我是 Avatar",
      "voice": "zh-TW-HsiaoChenNeural",  // 可選
      "speed": 1.0,                       // 可選 (0.5-2.0)
      "pitch": 1.0                        // 可選 (0.5-2.0)
    }
    \```

    ## Response
    - Content-Type: `audio/mpeg`
    - MP3 音訊檔案（16kbps, Mono）

    ## Response Headers
    \```
    Content-Type: audio/mpeg
    Content-Length: 24576
    X-Audio-Duration: 12.34
    Cache-Control: public, max-age=3600
    \```

    ## Error Response
    \```json
    {
      "error": "Missing required field: text",
      "code": "INVALID_REQUEST",
      "timestamp": "2025-10-14T10:30:00.000Z"
    }
    \```

    ## 狀態碼
    - `200`: 成功（返回音訊檔案）
    - `400`: 請求參數錯誤
    - `401`: 認證失敗
    - `408`: 請求超時
    - `500`: 伺服器錯誤

    ## 可用語音列表
    - `zh-TW-HsiaoChenNeural`: 女聲（預設）
    - `zh-TW-YunJheNeural`: 男聲
    - `zh-TW-HsiaoYuNeural`: 女聲（活潑）
    ```
  - [ ] 更新專案 README.md，加入 TTS API 使用說明
  - [ ] 執行完整測試流程，確保所有 AC 達成
  - [ ] 驗證 Console 無錯誤或警告訊息
  - [ ] 執行 TypeScript 型別檢查（`pnpm run type-check`）

---

## Dev Notes

### 相關來源樹（Source Tree）

根據架構文件，本 Story 涉及的檔案結構：

```
avatar-chat-poc/
├── app/
│   └── api/
│       └── tts/
│           └── route.ts        # TTS API 路由 (本 Story)
├── lib/
│   └── azure/
│       └── speech.ts           # Azure Speech 客戶端初始化 (本 Story)
├── types/
│   └── audio.ts                # Audio 相關型別定義 (擴充)
├── docs/
│   └── api/
│       └── tts.md              # TTS API 文件 (本 Story)
├── .env.local                  # 環境變數（開發用）
├── test-tts-api.sh             # 測試腳本（開發用）
└── test-audio.mp3              # 測試音訊檔案（臨時）
```

### 技術實作細節

**Azure Speech TTS 基本流程**：
```typescript
// 1. 建立 Speech 配置
const speechConfig = sdk.SpeechConfig.fromSubscription(apiKey, region);
speechConfig.speechSynthesisVoiceName = 'zh-TW-HsiaoChenNeural';
speechConfig.speechSynthesisOutputFormat = sdk.AudioOutputFormat.Audio16Khz32KBitRateMonoMp3;

// 2. 建立 TTS 合成器
const synthesizer = new sdk.SpeechSynthesizer(speechConfig, null);

// 3. 執行 TTS 轉換
synthesizer.speakTextAsync(
  text,
  (result) => {
    // 成功：取得音訊 Buffer
    const audioData = Buffer.from(result.audioData);
  },
  (error) => {
    // 失敗：處理錯誤
  }
);
```

**SSML (Speech Synthesis Markup Language) 格式**：
```xml
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-TW">
  <voice name="zh-TW-HsiaoChenNeural">
    <prosody rate="1.2" pitch="1.1">
      你好，我是 Avatar！
    </prosody>
  </voice>
</speak>
```

**為何使用 SSML？**
- ✅ **語速控制**: `rate` 屬性（0.5-2.0）
- ✅ **音調控制**: `pitch` 屬性（0.5-2.0）
- ✅ **語音控制**: `voice name` 屬性
- ✅ **進階功能**: 停頓、強調、發音糾正（未來可擴展）

**音訊格式選擇**：
```typescript
// 選擇: Audio16Khz32KBitRateMonoMp3
// 原因:
// ✅ MP3 格式（瀏覽器原生支援）
// ✅ 16kHz 採樣率（語音足夠）
// ✅ 32kbps 位元率（品質與檔案大小平衡）
// ✅ Mono（單聲道，語音足夠）

// 替代方案:
// - Audio24Khz48KBitRateMonoMp3（更高品質，檔案更大）
// - Audio16Khz128KBitRateMonoMp3（過度，不必要）
```

**超時控制實作**：
```typescript
const audioBuffer = await new Promise<Buffer>((resolve, reject) => {
  const timeoutId = setTimeout(() => {
    synthesizer.close();
    reject(new Error('TTS request timeout'));
  }, 5000);

  synthesizer.speakTextAsync(
    text,
    (result) => {
      clearTimeout(timeoutId);
      synthesizer.close();
      resolve(Buffer.from(result.audioData));
    },
    (error) => {
      clearTimeout(timeoutId);
      synthesizer.close();
      reject(error);
    }
  );
});
```

**音訊長度估算**：
```typescript
// MP3 位元率: 32kbps = 32 * 1024 bits/秒 = 4KB/秒
// 音訊檔案大小: 24KB
// 估算長度: 24KB / 4KB/秒 = 6 秒

const estimatedDuration = audioBuffer.length / (32 * 1024 / 8);
```

### 重要架構決策

1. **為何使用 Node.js Runtime 而非 Edge Runtime？**
   - ✅ **SDK 限制**: Azure Speech SDK 依賴 Node.js 特定 API
   - ❌ **Edge 不支援**: Edge Runtime 不支援 `child_process`, `fs` 等 API
   - ✅ **成本可接受**: TTS API 呼叫頻率低，Node.js Runtime 成本可控
   - ⚠️ **冷啟動較慢**: Node.js Runtime 冷啟動 ~500ms（可接受）

2. **為何選擇 zh-TW-HsiaoChenNeural 語音？**
   - ✅ **繁中支援**: 專為繁體中文優化
   - ✅ **Neural Voice**: 更自然的語音品質（vs Standard Voice）
   - ✅ **女聲**: 符合多數使用情境（可擴展男聲選項）
   - ✅ **成本**: Neural Voice 價格合理（$16/1M 字元）

3. **為何限制文字長度為 1000 字元？**
   - ✅ **成本控制**: 限制單次 TTS 呼叫成本
   - ✅ **使用者體驗**: 1000 字約 60 秒語音（已很長）
   - ✅ **超時風險**: 避免 TTS 轉換時間過長（> 5 秒）
   - ✅ **對話適用**: POC 對話通常 < 200 字，1000 字足夠

4. **為何加入 Cache-Control？**
   - ✅ **成本優化**: 相同文字可快取音訊，避免重複呼叫 API
   - ✅ **效能提升**: 快取音訊可立即播放，無需等待
   - ✅ **CDN 支援**: 未來可使用 CDN 快取音訊（如 Azure CDN）
   - ⚠️ **快取時間**: 1 小時（平衡快取效益與新鮮度）

5. **為何返回 X-Audio-Duration header？**
   - ✅ **客戶端便利**: 客戶端可預先知道音訊長度
   - ✅ **UI 優化**: 可顯示播放進度條、剩餘時間
   - ✅ **Lip Sync**: Story 3.6/3.7 會使用此資訊同步嘴型
   - ✅ **標準相容**: 使用 X- 前綴（自訂 header 慣例）

### Testing

**測試框架**: 手動測試 + Postman + 音訊播放器（POC 階段）

**測試範圍**:
1. ✅ API 路由建立成功，回應正確 HTTP 狀態碼
2. ✅ 正常文字轉語音，返回 MP3 音訊檔案
3. ✅ 音訊可正常播放，語音清晰
4. ✅ 繁體中文發音正確
5. ✅ 語速、音調調整正常運作
6. ✅ 請求驗證正確（缺少 text 返回 400）
7. ✅ 文字長度限制正確（> 1000 字返回 400）
8. ✅ 環境變數驗證正確（缺少 API Key 返回錯誤）
9. ✅ 超時控制正常（5 秒超時返回 408）
10. ✅ 錯誤分類正確（不同錯誤返回不同 code）

**測試執行方式**:
```bash
# 1. 啟動開發伺服器
pnpm dev

# 2. 測試正常文字轉語音（curl）
curl -X POST http://localhost:3000/api/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "你好，我是 Avatar"}' \
  --output test-audio.mp3

# 3. 播放音訊檔案
# Windows: test-audio.mp3（雙擊）
# macOS: afplay test-audio.mp3
# Linux: mpg123 test-audio.mp3

# 4. 測試語速調整
curl -X POST http://localhost:3000/api/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "快速朗讀測試", "speed": 1.5}' \
  --output test-fast.mp3

# 5. 測試錯誤處理（缺少 text）
curl -X POST http://localhost:3000/api/tts \
  -H "Content-Type: application/json" \
  -d '{}'

# 預期輸出（JSON）:
# {"error":"Missing required field: text","code":"INVALID_REQUEST","timestamp":"..."}

# 6. 使用 Postman 測試完整測試集合
```

**驗證清單**:
- [ ] `pnpm dev` 啟動無錯誤
- [ ] POST `/api/tts` 返回音訊檔案（Content-Type: audio/mpeg）
- [ ] 音訊檔案可正常播放
- [ ] 語音清晰、發音正確（繁體中文）
- [ ] 語速適中（約 3-4 字/秒）
- [ ] 語速調整正常（speed: 1.5 明顯較快）
- [ ] 音調調整正常（pitch: 1.2 明顯較高）
- [ ] 缺少 text 返回 400 錯誤
- [ ] 超長 text（> 1000 字）返回 400 錯誤
- [ ] 缺少環境變數時啟動失敗並有明確錯誤訊息
- [ ] X-Audio-Duration header 正確（與實際播放時長接近）
- [ ] Console 日誌顯示詳細錯誤資訊（開發模式）
- [ ] TypeScript 型別檢查通過

**Postman 測試集合範例**:
```json
{
  "info": {
    "name": "TTS API Tests",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "正常文字轉語音",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/tts",
        "header": [{"key": "Content-Type", "value": "application/json"}],
        "body": {
          "mode": "raw",
          "raw": "{\"text\":\"你好，我是 Avatar，很高興認識你！\"}"
        }
      }
    },
    {
      "name": "自訂語速（1.5 倍速）",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/tts",
        "body": {
          "mode": "raw",
          "raw": "{\"text\":\"這是快速朗讀測試\",\"speed\":1.5}"
        }
      }
    },
    {
      "name": "缺少 text 欄位（預期 400）",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/tts",
        "body": {
          "mode": "raw",
          "raw": "{}"
        }
      }
    }
  ]
}
```

### 效能考量

**TTS 轉換效能**:
- **轉換時間**: 通常 1-3 秒（取決於文字長度）
- **音訊大小**: 100 字約 10-15KB（32kbps MP3）
- **超時設定**: 5 秒（足夠大多數情況）

**成本分析**:
- **Azure Speech TTS 定價**: $16/1M 字元（Neural Voice）
- **單次呼叫**: 100 字 = $0.0016（約 NT$0.05）
- **POC 預算**: 1000 次對話 = $1.6（約 NT$50）
- **優化策略**: 快取常見回應、限制文字長度

**快取策略**:
- **快取位置**: 瀏覽器快取（Cache-Control: max-age=3600）
- **快取時間**: 1 小時
- **快取效益**: 相同文字可省略 API 呼叫，節省成本
- **未來優化**: 加入伺服器端快取（Redis）

**未來優化方向**（MVP 階段）:
1. **Response Streaming**: 使用 Azure Speech 串流 API（即時播放）
2. **Parallel TTS**: 長文字分段並行 TTS（降低延遲）
3. **CDN 快取**: 使用 Azure CDN 快取常見音訊
4. **Viseme Output**: 使用 Azure Speech Viseme API（精準 Lip Sync）

### 安全性考量

**API Key 安全**:
- ✅ 所有 Azure API Key 透過環境變數管理
- ✅ 環境變數不提交到 Git（`.env.local` 在 `.gitignore`）
- ✅ Azure Portal 配置生產環境變數（隔離）
- ⚠️ POC 階段無需用戶認證（公開存取）

**輸入驗證**:
- ✅ 驗證 text 欄位存在且非空
- ✅ 驗證 text 長度 ≤ 1000 字元
- ✅ 驗證 speed、pitch 範圍（0.5-2.0）
- ⚠️ 未驗證 text 內容（未來可加入內容過濾）

**錯誤訊息安全**:
- ✅ 錯誤訊息不洩漏敏感資訊（如 API Key）
- ✅ 使用通用錯誤訊息（「Internal server error」）
- ✅ 詳細錯誤僅記錄於 console（不返回客戶端）

**未來考量**（MVP 階段）:
- 加入請求頻率限制（Rate Limiting）
- 加入 CORS 設定（限制允許的來源）
- 加入請求大小限制（防止 DoS 攻擊）
- 加入內容過濾（避免不當文字轉語音）

### 依賴關係

**前置條件**:
- ✅ Story 1.1 已完成（Next.js 專案已建立）
- ✅ Story 1.2 已完成（Azure Speech 服務已註冊）
- ✅ 環境變數已配置（`AZURE_SPEECH_KEY`, `AZURE_SPEECH_REGION`）
- ✅ Node.js 18+ 與 pnpm 已安裝

**後續 Story 依賴**:
- **Story 3.6**: 會使用本 API 返回的音訊檔案，整合 Web Audio API 播放
- **Story 3.7**: 會整合完整對話流程（LLM → TTS → 播放 → Lip Sync）

**關鍵路徑**:
- 本 Story 與 Story 3.4（SSE 接收）並行開發，無阻塞依賴
- Story 3.6（Web Audio 播放）直接依賴本 API
- Story 3.7 整合所有 Epic 3 功能，最後完成

**與 Azure 服務整合**:
- **Azure Cognitive Services Speech**: 必須已建立資源
- **Azure Static Web Apps**: 環境變數需在 Azure Portal 配置
- **Node.js Runtime**: 確保 Next.js 13.4+ 支援（已滿足）

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-14 | 1.0 | 建立 Story 3.5 草稿 | SM Agent |

---

## Dev Agent Record

*(此部分由 Dev Agent 在實作時填寫)*

### Agent Model Used
_待填寫_

### Debug Log References
_待填寫_

### Completion Notes List
_待填寫_

### File List
_待填寫_

---

## QA Results

*(此部分由 QA Agent 在審核時填寫)*

_待填寫_
