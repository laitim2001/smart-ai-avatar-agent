# Story 3.7: 端到端對話流程整合與優化

## Status
Approved

---

## Story

**As a** 使用者,
**I want** 完整的對話流程順暢運作（輸入 → LLM → 顯示 → TTS → 播放），
**so that** 我可以自然地與 Avatar 對話。

---

## Acceptance Criteria

1. 完整流程：使用者輸入文字 → 送出 → 呼叫 Chat API（SSE 串流）→ LLM 回應即時顯示 → 回應完成後呼叫 TTS API → 音訊自動播放
2. 端到端延遲 < 2.5 秒（輸入送出到語音開始播放）
3. 錯誤處理完善：LLM 失敗顯示「Avatar 正在思考中...」、TTS 失敗顯示文字但無語音、網路中斷提示檢查連線
4. 可連續對話 10 輪無崩潰
5. 對話上下文正確保留（LLM 記得前面的對話）
6. UI Loading 狀態正確（輸入框禁用、按鈕 Spinner、音訊控制顯示）

---

## Tasks / Subtasks

- [ ] **Task 1: 驗證完整對話流程整合** (AC: 1)
  - [ ] 檢查 chatStore.sendMessage 邏輯完整：
    - [ ] 使用者輸入 → 建立使用者訊息
    - [ ] 呼叫 Chat API（SSE 串流）
    - [ ] 即時更新 Avatar 訊息
    - [ ] 回應完成後呼叫 audioStore.speakText
  - [ ] 檢查 audioStore.speakText 邏輯完整：
    - [ ] 呼叫 TTS API
    - [ ] 載入音訊 Buffer
    - [ ] 播放音訊
    - [ ] 更新播放狀態
  - [ ] 驗證資料流暢通無阻塞
  - [ ] 驗證錯誤不會中斷整體流程

- [ ] **Task 2: 實作端到端延遲監控** (AC: 2)
  - [ ] 在 chatStore 中加入效能監控：
    ```typescript
    sendMessage: async () => {
      const startTime = Date.now();

      // ... 現有邏輯

      await sendMessageAPI(
        chatMessages,
        onChunk,
        async (fullContent) => {
          const llmEndTime = Date.now();
          console.log(`[Performance] LLM Response Time: ${llmEndTime - startTime}ms`);

          // ... TTS 播放邏輯

          try {
            const ttsStartTime = Date.now();
            await speakText(fullContent);
            const ttsEndTime = Date.now();

            const totalTime = ttsEndTime - startTime;
            console.log(`[Performance] TTS Time: ${ttsEndTime - ttsStartTime}ms`);
            console.log(`[Performance] Total E2E Time: ${totalTime}ms`);

            if (totalTime > 2500) {
              console.warn(`[Performance] E2E delay exceeded target: ${totalTime}ms > 2500ms`);
            }
          } catch (error) {
            // 錯誤處理
          }
        },
        onError
      );
    },
    ```
  - [ ] 加入關鍵時間點記錄（送出、LLM 開始、LLM 完成、TTS 開始、播放開始）
  - [ ] 加入效能警告（超過 2.5 秒）
  - [ ] 測試並記錄實際延遲數據
  - [ ] 驗證延遲符合目標

- [ ] **Task 3: 完善錯誤處理與降級方案** (AC: 3)
  - [ ] 實作 LLM 錯誤處理：
    ```typescript
    onError: (error) => {
      console.error('[Chat Error]', error);

      // 分類錯誤類型
      let errorMessage = '抱歉，我遇到了一些問題。';

      if (error.message.includes('network') || error.message.includes('fetch failed')) {
        errorMessage = '網路連線不穩定，請檢查網路設定。';
      } else if (error.message.includes('timeout')) {
        errorMessage = 'Avatar 正在思考中，請稍候再試...';
      } else if (error.message.includes('quota')) {
        errorMessage = 'Avatar 目前忙碌中，請稍後再試。';
      }

      // 移除臨時 Avatar 訊息，加入錯誤訊息
      set((state) => ({
        messages: [
          ...state.messages.filter(m => m.id !== avatarMessageId),
          {
            id: `error-${Date.now()}`,
            role: 'avatar',
            content: errorMessage,
            timestamp: new Date()
          }
        ],
        isLoading: false
      }));
    }
    ```
  - [ ] 實作 TTS 錯誤處理（降級方案）：
    ```typescript
    try {
      await speakText(fullContent);
    } catch (ttsError) {
      console.error('[TTS Error]', ttsError);
      // TTS 失敗不影響對話，僅無語音
      // 使用者仍可看到文字回應
    }
    ```
  - [ ] 實作網路連線檢查：
    ```typescript
    if (!navigator.onLine) {
      throw new Error('網路連線中斷，請檢查網路設定');
    }
    ```
  - [ ] 測試各種錯誤情境（LLM 失敗、TTS 失敗、網路中斷）
  - [ ] 驗證錯誤訊息友善且明確

- [ ] **Task 4: 實作連續對話壓力測試** (AC: 4)
  - [ ] 建立測試腳本 `test-continuous-conversation.ts`（開發用）：
    ```typescript
    /**
     * 連續對話壓力測試
     * 測試 10 輪連續對話，驗證無崩潰
     */
    import { useChatStore } from '@/stores/chatStore';

    async function testContinuousConversation() {
      const { setInput, sendMessage } = useChatStore.getState();

      const testMessages = [
        '你好',
        '我叫小明',
        '你還記得我的名字嗎？',
        '今天天氣如何？',
        '請介紹一下你自己',
        '你會做什麼？',
        '你喜歡什麼顏色？',
        '謝謝你',
        '再見',
        '下次見'
      ];

      for (let i = 0; i < testMessages.length; i++) {
        console.log(`\n[Test Round ${i + 1}/${testMessages.length}]`);
        console.log(`Input: ${testMessages[i]}`);

        setInput(testMessages[i]);
        await sendMessage();

        // 等待回應完成（模擬）
        await new Promise(resolve => setTimeout(resolve, 5000));

        console.log(`Round ${i + 1} completed`);
      }

      console.log('\n✅ All rounds completed successfully');
    }

    // 執行測試（在瀏覽器 Console 中）
    // testContinuousConversation();
    ```
  - [ ] 手動執行 10 輪連續對話測試
  - [ ] 監控記憶體使用（Chrome DevTools > Memory）
  - [ ] 監控效能（Chrome DevTools > Performance）
  - [ ] 驗證無崩潰、無記憶體洩漏
  - [ ] 記錄測試結果

- [ ] **Task 5: 驗證對話上下文保留** (AC: 5)
  - [ ] 測試上下文對話：
    ```
    Round 1: 「我叫小明」
    Round 2: 「你還記得我的名字嗎？」
    → 預期回應包含「小明」

    Round 3: 「我喜歡藍色」
    Round 4: 「我喜歡什麼顏色？」
    → 預期回應包含「藍色」

    Round 5: 「請用一句話總結我們的對話」
    → 預期回應包含前面對話的關鍵資訊
    ```
  - [ ] 驗證 LLM 正確記憶對話內容
  - [ ] 驗證對話歷史長度限制正常（最近 20 則訊息）
  - [ ] 測試清除對話功能（清除後 LLM 不記得）
  - [ ] 驗證上下文管理邏輯正確

- [ ] **Task 6: 優化 UI Loading 狀態協調** (AC: 6)
  - [ ] 檢查所有 Loading 狀態同步：
    ```typescript
    // chatStore.isLoading 控制:
    - 輸入框 disabled
    - 送出按鈕 Spinner
    - 清除按鈕 disabled

    // audioStore.state 控制:
    - AudioControls 顯示/隱藏
    - 播放/暫停按鈕狀態
    - 「正在播放」提示

    // 協調邏輯:
    - chatStore.isLoading = true → 輸入禁用
    - LLM 回應完成 → chatStore.isLoading = false
    - TTS 開始 → audioStore.state = LOADING
    - 播放開始 → audioStore.state = PLAYING
    - 播放結束 → audioStore.state = IDLE
    ```
  - [ ] 加入 Loading 狀態協調說明註解
  - [ ] 測試所有 Loading 狀態顯示正確
  - [ ] 驗證使用者體驗流暢

- [ ] **Task 7: 建立端到端測試文件** (AC: 1-6)
  - [ ] 建立 `docs/testing/e2e-conversation-test.md` 文件：
    ```markdown
    # 端到端對話流程測試

    ## 測試目標
    驗證完整對話流程順暢運作，符合所有 Acceptance Criteria。

    ## 測試環境
    - 瀏覽器: Chrome 90+
    - 網路: 穩定寬頻連線
    - 裝置: 桌機/筆電

    ## 測試案例

    ### TC1: 正常對話流程
    **步驟**:
    1. 輸入「你好」並送出
    2. 觀察 SSE 串流回應（逐字顯示）
    3. 觀察回應完成後自動播放語音
    4. 驗證語音清晰、發音正確

    **預期結果**:
    - LLM 回應即時顯示 ✅
    - 語音自動播放 ✅
    - 端到端延遲 < 2.5 秒 ✅

    ### TC2: 連續對話
    **步驟**:
    1. 連續輸入 10 則訊息
    2. 每則訊息間隔 5 秒
    3. 觀察每則回應與語音

    **預期結果**:
    - 所有回應正確顯示 ✅
    - 所有語音正確播放 ✅
    - 無崩潰或錯誤 ✅

    ### TC3: 上下文對話
    **步驟**:
    1. 輸入「我叫小明」
    2. 輸入「你還記得我的名字嗎？」
    3. 驗證回應包含「小明」

    **預期結果**:
    - LLM 記得前面對話 ✅
    - 上下文正確保留 ✅

    ### TC4: 錯誤處理
    **步驟**:
    1. 關閉網路連線
    2. 輸入訊息並送出
    3. 觀察錯誤訊息

    **預期結果**:
    - 顯示「網路連線不穩定」✅
    - 對話不崩潰 ✅

    ### TC5: Loading 狀態
    **步驟**:
    1. 輸入訊息並送出
    2. 觀察 Loading 狀態變化

    **預期結果**:
    - 輸入框禁用 ✅
    - 送出按鈕顯示 Spinner ✅
    - 音訊控制正確顯示 ✅

    ## 效能指標
    - 端到端延遲: < 2.5 秒 (目標)
    - LLM 回應時間: < 2 秒 (目標)
    - TTS 轉換時間: < 1.5 秒 (目標)
    - 記憶體使用: < 500 MB (目標)

    ## 通過標準
    - 所有測試案例通過 ✅
    - 效能指標達標 ✅
    - 無嚴重錯誤或崩潰 ✅
    ```
  - [ ] 建立測試檢查清單
  - [ ] 執行完整測試流程
  - [ ] 記錄測試結果與效能數據
  - [ ] 驗證所有 AC 達成

- [ ] **Task 8: 效能優化與最終驗證** (AC: 2)
  - [ ] 分析效能瓶頸：
    - [ ] 使用 Chrome DevTools Performance 記錄對話流程
    - [ ] 識別延遲最大的環節（LLM、TTS、網路）
    - [ ] 評估優化可行性
  - [ ] 實作效能優化（如需要）：
    ```typescript
    // 優化 1: TTS API 快取（相同文字）
    const ttsCache = new Map<string, Blob>();

    async function getCachedTTS(text: string): Promise<Blob> {
      if (ttsCache.has(text)) {
        console.log('[TTS Cache] Hit');
        return ttsCache.get(text)!;
      }

      const response = await fetch('/api/tts', { ... });
      const blob = await response.blob();
      ttsCache.set(text, blob);
      return blob;
    }

    // 優化 2: 預先載入常見回應
    const COMMON_RESPONSES = [
      '你好',
      '很高興認識你',
      '再見'
    ];

    async function preloadCommonResponses() {
      for (const text of COMMON_RESPONSES) {
        await getCachedTTS(text);
      }
    }
    ```
  - [ ] 測試優化效果
  - [ ] 驗證端到端延遲達標（< 2.5 秒）
  - [ ] 記錄最終效能數據

- [ ] **Task 9: 建立使用者指南** (AC: 相關)
  - [ ] 建立 `docs/user-guide.md` 使用者指南：
    ```markdown
    # 3D Avatar 對話系統使用指南

    ## 快速開始

    1. **開啟應用**
       - 在瀏覽器中開啟 `http://localhost:3000`（開發環境）
       - 或開啟已部署的 Azure URL（生產環境）

    2. **選擇 Avatar**（如有選擇器）
       - 點擊喜歡的 Avatar 卡片
       - 等待 Avatar 載入完成

    3. **開始對話**
       - 在輸入框中輸入訊息（如「你好」）
       - 按 Enter 或點擊「送出」按鈕
       - 等待 Avatar 回應（會即時顯示）
       - 回應完成後會自動播放語音

    ## 功能說明

    ### 對話介面
    - **輸入框**: 輸入訊息與 Avatar 對話
    - **送出按鈕**: 送出訊息（或按 Enter）
    - **清除按鈕**: 清除所有對話記錄
    - **對話歷史**: 顯示最近 5 則訊息

    ### 音訊控制
    - **播放/暫停**: 控制語音播放
    - **停止**: 停止當前語音
    - **播放狀態**: 顯示當前播放的文字

    ### Avatar 顯示
    - **3D 渲染**: 即時渲染 3D Avatar
    - **待機動畫**: Avatar 會自然呼吸、眨眼
    - **旋轉視角**: 使用滑鼠拖曳旋轉視角（開發模式）

    ## 常見問題

    **Q: 為什麼沒有聲音？**
    A: 檢查音量設定、確認 TTS API 正常運作。

    **Q: 對話很慢怎麼辦？**
    A: 檢查網路連線、Azure API 狀態。

    **Q: Avatar 說錯話怎麼辦？**
    A: 這是 LLM 的限制，可重新提問或清除對話重新開始。

    ## 技術限制

    - **POC 階段**: 僅支援文字對話（語音輸入為選做）
    - **瀏覽器**: 需支援 WebGL 2.0 與 Web Audio API
    - **網路**: 需穩定網路連線（LLM 與 TTS 為雲端服務）
    - **對話歷史**: 最多保留 20 則訊息（10 輪對話）

    ## 聯絡支援

    如遇到問題，請聯絡開發團隊。
    ```
  - [ ] 加入截圖與操作示範
  - [ ] 驗證指南清晰易懂
  - [ ] 更新專案 README.md 連結至使用者指南

---

## Dev Notes

### 相關來源樹（Source Tree）

根據架構文件，本 Story 涉及的檔案結構：

```
avatar-chat-poc/
├── stores/
│   ├── chatStore.ts               # 加入效能監控 (重構)
│   └── audioStore.ts              # 確保整合正確
├── docs/
│   ├── testing/
│   │   └── e2e-conversation-test.md  # 端到端測試文件 (本 Story)
│   └── user-guide.md              # 使用者指南 (本 Story)
└── test-continuous-conversation.ts  # 測試腳本（開發用）
```

### 技術實作細節

**端到端流程時序圖**：
```
使用者輸入 「你好」 並送出
  ↓ (0ms)
chatStore.sendMessage() 開始
  ↓
建立使用者訊息 → 加入 messages
  ↓
呼叫 /api/chat (POST with SSE)
  ↓ (~500ms)
SSE 串流開始
  ↓ (~1000ms - 逐字)
LLM 回應完成 「你好！我是 Avatar」
  ↓
chatStore onComplete 觸發
  ↓
呼叫 audioStore.speakText()
  ↓ (~200ms)
呼叫 /api/tts (POST)
  ↓ (~1000ms)
TTS 轉換完成，返回 MP3
  ↓ (~100ms)
載入 AudioBuffer
  ↓ (~50ms)
開始播放語音
  ↓
總延遲: ~2850ms (略超目標，可優化)
```

**效能優化策略**：
```typescript
// 1. TTS 快取（相同文字不重複呼叫 API）
const ttsCache = new Map<string, Blob>();

// 2. 預先載入常見回應（減少首次延遲）
preloadCommonResponses(['你好', '再見', '謝謝']);

// 3. 平行執行（TTS 與 UI 更新並行）
Promise.all([
  speakText(fullContent),
  updateMessages(fullContent)
]);

// 4. 串流 TTS（未來優化，使用 Azure Speech 串流 API）
```

**錯誤處理策略**：
```typescript
// 1. LLM 錯誤 → 顯示錯誤訊息，不中斷對話
catch (llmError) {
  showErrorMessage('Avatar 正在思考中...');
  // 使用者可繼續輸入下一則訊息
}

// 2. TTS 錯誤 → 降級為僅文字，不中斷對話
catch (ttsError) {
  console.error('TTS failed:', ttsError);
  // 文字回應仍正常顯示，僅無語音
}

// 3. 網路錯誤 → 明確提示使用者
if (!navigator.onLine) {
  showErrorMessage('網路連線中斷，請檢查網路設定');
}
```

**上下文管理策略**：
```typescript
// 限制對話歷史長度（避免 token 超限）
const MAX_HISTORY = 20; // 10 輪對話

const recentMessages = messages.slice(-MAX_HISTORY);

// 轉換為 API 格式（包含 system prompt）
const apiMessages = [
  { role: 'system', content: SYSTEM_PROMPT },
  ...recentMessages.map(m => ({
    role: m.role === 'avatar' ? 'assistant' : 'user',
    content: m.content
  }))
];
```

### 重要架構決策

1. **為何不實作語音輸入（STT）？**
   - ✅ **POC 範圍**: 語音輸入為選做功能（FR9）
   - ✅ **優先順序**: 專注於核心功能（文字對話 + TTS）
   - ✅ **時間限制**: 4 週 POC，文字對話足夠驗證技術
   - 📝 **未來擴展**: MVP 階段可加入 Web Speech API 或 Azure STT

2. **為何端到端延遲目標設為 2.5 秒？**
   - ✅ **使用者體驗**: 2.5 秒是對話可接受延遲上限
   - ✅ **技術限制**: LLM (~1s) + TTS (~1.5s) = ~2.5s（已接近極限）
   - ✅ **優化空間**: 可透過快取、預載、串流等方式優化
   - ⚠️ **實際表現**: 首次對話可能略超 2.5s（冷啟動），後續會更快

3. **為何 TTS 失敗不中斷對話？**
   - ✅ **降級方案**: 保證核心功能（文字對話）可用
   - ✅ **使用者體驗**: 使用者仍可看到文字回應
   - ✅ **錯誤處理**: TTS 為增強功能，非必要功能
   - ✅ **除錯方便**: 開發階段 TTS 失敗不影響對話測試

4. **為何限制對話歷史為 20 則訊息？**
   - ✅ **Token 限制**: GPT-4 Turbo 有 token 限制（128K，但成本考量）
   - ✅ **成本控制**: 減少輸入 tokens，降低 API 成本
   - ✅ **效能優化**: 減少請求大小與處理時間
   - ✅ **使用者體驗**: 20 則訊息（10 輪）足夠大多數對話情境

5. **為何需要效能監控？**
   - ✅ **數據驅動**: 透過數據識別效能瓶頸
   - ✅ **目標驗證**: 確保端到端延遲達標
   - ✅ **除錯工具**: 開發階段可快速定位問題
   - ✅ **未來優化**: 為 MVP 階段優化提供基準

### Testing

**測試框架**: 手動測試 + 效能監控 + 壓力測試（POC 階段）

**測試範圍**:
1. ✅ 完整對話流程正常運作
2. ✅ 端到端延遲 < 2.5 秒
3. ✅ 錯誤處理完善（LLM、TTS、網路）
4. ✅ 連續對話 10 輪無崩潰
5. ✅ 對話上下文正確保留
6. ✅ UI Loading 狀態正確協調
7. ✅ 記憶體使用穩定（無洩漏）
8. ✅ 效能數據記錄完整

**測試執行方式**:
```bash
# 1. 啟動開發伺服器
pnpm dev

# 2. 開啟應用
http://localhost:3000

# 3. 執行端到端測試（參考 docs/testing/e2e-conversation-test.md）

# 4. 連續對話測試
- 快速連續輸入 10 則訊息
- 觀察每則回應與語音
- 監控 Chrome DevTools Memory

# 5. 效能測試
- 開啟 Chrome DevTools > Performance
- 記錄完整對話流程
- 分析各階段延遲
- 驗證端到端延遲 < 2.5 秒

# 6. 錯誤處理測試
- 測試 LLM 失敗情境
- 測試 TTS 失敗情境
- 測試網路中斷情境
```

**驗證清單**:
- [ ] 完整對話流程順暢無阻塞
- [ ] 端到端延遲 < 2.5 秒（90% 案例）
- [ ] LLM 回應即時顯示（SSE 串流）
- [ ] TTS 語音自動播放
- [ ] 語音清晰、發音正確
- [ ] LLM 失敗顯示友善錯誤訊息
- [ ] TTS 失敗不影響文字顯示
- [ ] 網路中斷提示正確
- [ ] 連續 10 輪對話無崩潰
- [ ] 對話上下文正確保留
- [ ] 輸入框 Loading 狀態正確
- [ ] 音訊控制 Loading 狀態正確
- [ ] 記憶體使用穩定（< 500 MB）
- [ ] Console 無嚴重錯誤
- [ ] 效能數據記錄完整

### 效能考量

**端到端延遲目標分解**：
```
目標: < 2.5 秒

實際測量:
- LLM 首字回應: ~800ms
- LLM 完整回應: ~1500ms
- TTS API 呼叫: ~200ms
- TTS 轉換: ~1000ms
- 音訊載入: ~100ms
- 播放開始: ~50ms
---
總計: ~2650ms (略超目標)

優化策略:
- TTS 快取: 節省 ~1000ms（相同文字）
- 預先載入: 節省 ~100ms（常見回應）
- 串流 TTS: 節省 ~500ms（未來）
---
優化後: ~1650ms (達標)
```

**記憶體使用分析**：
```
初始載入: ~50 MB
對話 10 輪:
- messages 陣列: ~10 KB
- AudioBuffer: ~50 KB/則
- Blob URLs: ~50 KB/則
- 其他狀態: ~5 KB
---
總增長: ~1 MB/10 輪 (可接受)

記憶體優化:
- 限制 messages 長度
- 及時釋放 Blob URLs
- AudioContext 單例模式
---
預期: < 500 MB (長時間使用)
```

**未來優化方向**（MVP 階段）:
1. **Streaming TTS**: 使用 Azure Speech 串流 API（即時播放）
2. **Response Caching**: 快取常見問題回應（LLM + TTS）
3. **Predictive Loading**: 預測下一個可能問題，預先載入音訊
4. **CDN Integration**: 使用 Azure CDN 快取 TTS 音訊

### 安全性考量

**端到端安全**:
- ✅ 所有 API 請求透過 HTTPS（生產環境）
- ✅ 無敏感資料在對話中傳輸（僅文字內容）
- ✅ 錯誤訊息不洩漏系統資訊
- ⚠️ POC 階段無用戶認證（公開存取）

**資料隱私**:
- ✅ 對話資料僅存於瀏覽器（無後端儲存）
- ✅ Azure API 呼叫遵守 GDPR（Azure 合規）
- ⚠️ 對話內容傳送至 Azure OpenAI（雲端處理）

**未來考量**（MVP 階段）:
- 加入用戶認證（Azure AD B2C）
- 加入對話加密（端到端加密）
- 加入內容過濾（避免不當對話）
- 加入 Rate Limiting（防止濫用）

### 依賴關係

**前置條件**:
- ✅ Story 3.1-3.6 全部完成
- ✅ 所有 Azure 服務已配置
- ✅ 環境變數已設定
- ✅ Node.js 18+ 與 pnpm 已安裝

**後續 Epic 依賴**:
- **Epic 4**: Lip Sync 功能將使用本 Story 的完整對話流程
- **Epic 5**: 最終優化與部署將基於本 Story 的端到端流程

**關鍵路徑**:
- 本 Story 是 Epic 3 的最終整合與驗證
- 完成後 Epic 3 所有功能達標
- 為 Epic 4（Lip Sync）準備完整對話流程

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-14 | 1.0 | 建立 Story 3.7 草稿 | SM Agent |

---

## Dev Agent Record

*(此部分由 Dev Agent 在實作時填寫)*

### Agent Model Used
_待填寫_

### Debug Log References
_待填寫_

### Completion Notes List
_待填寫_

### File List
_待填寫_

---

## QA Results

*(此部分由 QA Agent 在審核時填寫)*

_待填寫_
