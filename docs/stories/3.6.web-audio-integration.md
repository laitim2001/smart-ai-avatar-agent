# Story 3.6: Web Audio API 音訊播放整合

## Status
Approved

---

## Story

**As a** 使用者,
**I want** Avatar 的回應自動以語音播放，
**so that** 我可以聽到 Avatar 的「聲音」。

---

## Acceptance Criteria

1. 建立 `lib/utils/audio.ts`，實作 Web Audio API 播放函式
2. LLM 回應完成後，自動呼叫 `/api/tts` 取得音訊
3. 將音訊轉換為 `AudioBuffer`
4. 使用 `AudioContext` 播放音訊
5. 播放時更新 `audioStore` 狀態（`isPlaying: true`）
6. 播放完畢後重置狀態（`isPlaying: false`）
7. 支援播放控制：暫停、繼續、停止（UI 按鈕）
8. 測試：對話後自動播放語音，聲音清晰無延遲（< 1.5s）

---

## Tasks / Subtasks

- [ ] **Task 1: 建立 Web Audio 播放函式** (AC: 1, 3, 4)
  - [ ] 建立目錄 `lib/utils/`（如尚未存在）
  - [ ] 建立 `lib/utils/audio.ts` 檔案
  - [ ] 實作 Web Audio API 播放邏輯：
    ```typescript
    /**
     * Web Audio API 播放管理器
     */
    export class AudioPlayer {
      private audioContext: AudioContext | null = null;
      private currentSource: AudioBufferSourceNode | null = null;
      private currentBuffer: AudioBuffer | null = null;
      private startTime: number = 0;
      private pauseTime: number = 0;
      private isPaused: boolean = false;

      /**
       * 初始化 AudioContext
       */
      private initAudioContext() {
        if (!this.audioContext) {
          this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        }
        return this.audioContext;
      }

      /**
       * 載入音訊檔案並轉換為 AudioBuffer
       * @param audioUrl 音訊檔案 URL 或 Blob URL
       */
      async loadAudio(audioUrl: string): Promise<AudioBuffer> {
        const context = this.initAudioContext();

        // 下載音訊檔案
        const response = await fetch(audioUrl);
        const arrayBuffer = await response.arrayBuffer();

        // 解碼為 AudioBuffer
        const audioBuffer = await context.decodeAudioData(arrayBuffer);

        this.currentBuffer = audioBuffer;
        return audioBuffer;
      }

      /**
       * 播放音訊
       * @param audioBuffer 可選，如未提供則使用當前 buffer
       * @param onEnded 播放結束回調
       */
      play(audioBuffer?: AudioBuffer, onEnded?: () => void): void {
        const context = this.initAudioContext();
        const buffer = audioBuffer || this.currentBuffer;

        if (!buffer) {
          throw new Error('No audio buffer available');
        }

        // 停止當前播放
        this.stop();

        // 建立音訊源節點
        const source = context.createBufferSource();
        source.buffer = buffer;
        source.connect(context.destination);

        // 設定播放結束回調
        source.onended = () => {
          this.currentSource = null;
          this.isPaused = false;
          if (onEnded) onEnded();
        };

        // 開始播放
        source.start(0, this.isPaused ? this.pauseTime : 0);
        this.currentSource = source;
        this.startTime = context.currentTime - (this.isPaused ? this.pauseTime : 0);
        this.isPaused = false;
      }

      /**
       * 暫停播放
       */
      pause(): void {
        if (this.currentSource && this.audioContext && !this.isPaused) {
          this.pauseTime = this.audioContext.currentTime - this.startTime;
          this.stop();
          this.isPaused = true;
        }
      }

      /**
       * 恢復播放
       */
      resume(): void {
        if (this.isPaused && this.currentBuffer) {
          this.play(this.currentBuffer);
        }
      }

      /**
       * 停止播放
       */
      stop(): void {
        if (this.currentSource) {
          try {
            this.currentSource.stop();
          } catch (error) {
            // 已經停止，忽略錯誤
          }
          this.currentSource = null;
        }
        this.pauseTime = 0;
        this.isPaused = false;
      }

      /**
       * 取得當前播放位置（秒）
       */
      getCurrentTime(): number {
        if (!this.audioContext) return 0;
        if (this.isPaused) return this.pauseTime;
        if (this.currentSource) {
          return this.audioContext.currentTime - this.startTime;
        }
        return 0;
      }

      /**
       * 取得音訊長度（秒）
       */
      getDuration(): number {
        return this.currentBuffer?.duration || 0;
      }

      /**
       * 清理資源
       */
      dispose(): void {
        this.stop();
        if (this.audioContext) {
          this.audioContext.close();
          this.audioContext = null;
        }
      }
    }

    /**
     * 建立全域 AudioPlayer 實例（單例模式）
     */
    let globalAudioPlayer: AudioPlayer | null = null;

    export function getAudioPlayer(): AudioPlayer {
      if (!globalAudioPlayer) {
        globalAudioPlayer = new AudioPlayer();
      }
      return globalAudioPlayer;
    }
    ```
  - [ ] 加入 JSDoc 註解說明每個方法用途
  - [ ] 實作錯誤處理（AudioContext 不支援、解碼失敗等）
  - [ ] 驗證播放函式可正常運作

- [ ] **Task 2: 整合 TTS API 呼叫與音訊播放** (AC: 2)
  - [ ] 開啟 `stores/audioStore.ts`
  - [ ] 整合 TTS API 呼叫與播放邏輯：
    ```typescript
    import { getAudioPlayer } from '@/lib/utils/audio';

    export const useAudioStore = create<AudioStore>((set, get) => ({
      // ... 現有 state

      /**
       * 文字轉語音並播放
       * @param text 要轉換的文字
       */
      async speakText(text: string): Promise<void> {
        try {
          // 停止當前播放
          const { stopAudio } = get();
          stopAudio();

          // 更新狀態為 Loading
          set({ state: AudioState.LOADING });

          // 呼叫 TTS API
          const response = await fetch('/api/tts', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ text }),
          });

          if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error || 'TTS API request failed');
          }

          // 取得音訊 Blob
          const audioBlob = await response.blob();
          const audioUrl = URL.createObjectURL(audioBlob);

          // 載入音訊
          const audioPlayer = getAudioPlayer();
          const audioBuffer = await audioPlayer.loadAudio(audioUrl);

          // 建立 AudioItem
          const audioItem: AudioItem = {
            id: `audio-${Date.now()}`,
            url: audioUrl,
            text: text,
            duration: audioBuffer.duration,
            timestamp: new Date()
          };

          // 更新狀態並播放
          set({
            currentAudio: audioItem,
            state: AudioState.PLAYING
          });

          audioPlayer.play(audioBuffer, () => {
            // 播放結束回調
            set({
              currentAudio: null,
              state: AudioState.IDLE
            });

            // 清理 Blob URL
            URL.revokeObjectURL(audioUrl);
          });

        } catch (error) {
          console.error('[Audio Error]', error);
          set({
            currentAudio: null,
            state: AudioState.IDLE
          });
          throw error;
        }
      },

      // ... 其他 actions
    }));
    ```
  - [ ] 實作 TTS API 呼叫邏輯
  - [ ] 實作音訊 Blob 轉 AudioBuffer
  - [ ] 實作播放結束回調（清理狀態）
  - [ ] 驗證整合邏輯正確

- [ ] **Task 3: 實作播放控制 Actions** (AC: 5, 6, 7)
  - [ ] 在 `audioStore.ts` 中實作播放控制：
    ```typescript
    pauseAudio: () => {
      const { state } = get();
      if (state === AudioState.PLAYING) {
        const audioPlayer = getAudioPlayer();
        audioPlayer.pause();
        set({ state: AudioState.PAUSED });
      }
    },

    resumeAudio: () => {
      const { state } = get();
      if (state === AudioState.PAUSED) {
        const audioPlayer = getAudioPlayer();
        audioPlayer.resume();
        set({ state: AudioState.PLAYING });
      }
    },

    stopAudio: () => {
      const audioPlayer = getAudioPlayer();
      audioPlayer.stop();
      set({
        currentAudio: null,
        state: AudioState.IDLE
      });
    },
    ```
  - [ ] 實作 pause、resume、stop 邏輯
  - [ ] 更新 audioStore 狀態（PLAYING, PAUSED, IDLE）
  - [ ] 測試播放控制功能正常運作
  - [ ] 驗證狀態轉換正確

- [ ] **Task 4: 整合自動播放至對話流程** (AC: 2, 8)
  - [ ] 開啟 `stores/chatStore.ts`
  - [ ] 在 LLM 回應完成後觸發 TTS：
    ```typescript
    import { useAudioStore } from './audioStore';

    export const useChatStore = create<ChatStore>((set, get) => ({
      // ...

      sendMessage: async () => {
        // ... 現有 SSE 接收邏輯

        await sendMessageAPI(
          chatMessages,
          onChunk,
          // onComplete: 完成後呼叫 TTS
          async (fullContent) => {
            set((state) => ({
              messages: state.messages.map(m =>
                m.id === avatarMessageId
                  ? { ...m, content: fullContent, timestamp: new Date() }
                  : m
              ),
              isLoading: false
            }));

            // 自動播放語音
            try {
              const { speakText } = useAudioStore.getState();
              await speakText(fullContent);
            } catch (error) {
              console.error('[TTS Error]', error);
              // 錯誤不中斷對話流程（僅無語音）
            }
          },
          onError
        );
      },

      // ...
    }));
    ```
  - [ ] 在 LLM 回應完成時自動呼叫 `speakText`
  - [ ] 實作錯誤處理（TTS 失敗不影響對話）
  - [ ] 測試自動播放功能
  - [ ] 驗證播放延遲 < 1.5 秒

- [ ] **Task 5: 建立音訊控制 UI 組件** (AC: 7)
  - [ ] 建立 `components/chat/AudioControls.tsx` 組件：
    ```typescript
    'use client';

    import { useAudioStore } from '@/stores/audioStore';
    import { AudioState } from '@/types/audio';

    export default function AudioControls() {
      const { state, currentAudio, pauseAudio, resumeAudio, stopAudio } = useAudioStore();

      if (!currentAudio) return null;

      return (
        <div className="fixed bottom-4 left-4 bg-white rounded-lg shadow-lg p-4 flex items-center space-x-4">
          {/* 播放/暫停按鈕 */}
          {state === AudioState.PLAYING ? (
            <button
              onClick={pauseAudio}
              className="bg-blue-600 text-white p-2 rounded-full hover:bg-blue-700 transition-colors"
              aria-label="暫停"
            >
              <PauseIcon className="w-6 h-6" />
            </button>
          ) : state === AudioState.PAUSED ? (
            <button
              onClick={resumeAudio}
              className="bg-blue-600 text-white p-2 rounded-full hover:bg-blue-700 transition-colors"
              aria-label="繼續播放"
            >
              <PlayIcon className="w-6 h-6" />
            </button>
          ) : (
            <div className="p-2">
              <Spinner className="w-6 h-6" />
            </div>
          )}

          {/* 停止按鈕 */}
          <button
            onClick={stopAudio}
            className="bg-gray-200 text-gray-700 p-2 rounded-full hover:bg-gray-300 transition-colors"
            aria-label="停止"
          >
            <StopIcon className="w-6 h-6" />
          </button>

          {/* 當前播放文字（截斷） */}
          <div className="flex-1 max-w-xs">
            <p className="text-sm text-gray-700 truncate">
              正在播放：{currentAudio.text}
            </p>
            <p className="text-xs text-gray-500">
              {state === AudioState.PAUSED ? '已暫停' : '播放中...'}
            </p>
          </div>
        </div>
      );
    }

    // 簡單的 Icon 組件（使用 SVG）
    function PlayIcon({ className }: { className?: string }) {
      return (
        <svg className={className} fill="currentColor" viewBox="0 0 24 24">
          <path d="M8 5v14l11-7z" />
        </svg>
      );
    }

    function PauseIcon({ className }: { className?: string }) {
      return (
        <svg className={className} fill="currentColor" viewBox="0 0 24 24">
          <path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z" />
        </svg>
      );
    }

    function StopIcon({ className }: { className?: string }) {
      return (
        <svg className={className} fill="currentColor" viewBox="0 0 24 24">
          <rect x="6" y="6" width="12" height="12" />
        </svg>
      );
    }
    ```
  - [ ] 實作播放/暫停/停止按鈕
  - [ ] 實作當前播放文字顯示
  - [ ] 實作播放狀態提示（播放中/已暫停）
  - [ ] 加入 Tailwind CSS 樣式
  - [ ] 驗證 UI 組件正常運作

- [ ] **Task 6: 整合音訊控制組件至主頁面** (AC: 7)
  - [ ] 開啟 `app/page.tsx`
  - [ ] 引入 AudioControls 組件：
    ```typescript
    import AudioControls from '@/components/chat/AudioControls';

    export default function Home() {
      return (
        <main className="flex h-screen bg-gradient-to-b from-slate-900 to-slate-800">
          {/* 左側：Avatar 顯示區 */}
          <div className="flex-1">
            <AvatarCanvas />
          </div>

          {/* 右側：對話介面 */}
          <div className="w-96 p-4">
            <ChatInterface />
          </div>

          {/* 音訊控制（浮動） */}
          <AudioControls />
        </main>
      );
    }
    ```
  - [ ] 測試音訊控制組件顯示位置正確（左下角浮動）
  - [ ] 測試控制按鈕互動功能
  - [ ] 驗證 UI 整合正確

- [ ] **Task 7: 實作音訊佇列管理（選用優化）** (AC: 相關)
  - [ ] 在 `audioStore.ts` 中實作佇列邏輯：
    ```typescript
    addToQueue: (audio: AudioItem) => {
      set((state) => ({
        queue: [...state.queue, audio]
      }));
    },

    playNext: async () => {
      const { queue, speakText } = get();
      if (queue.length > 0) {
        const [nextAudio, ...remainingQueue] = queue;
        set({ queue: remainingQueue });
        await speakText(nextAudio.text);
      }
    },

    clearQueue: () => {
      set({ queue: [] });
    },
    ```
  - [ ] 實作佇列加入邏輯
  - [ ] 實作自動播放下一個音訊
  - [ ] 實作清空佇列
  - [ ] 測試佇列功能（連續多則訊息）
  - [ ] 驗證佇列邏輯正確

- [ ] **Task 8: 整合測試與驗證** (AC: 1-8)
  - [ ] 執行 `pnpm dev` 啟動開發伺服器
  - [ ] 開啟 `http://localhost:3000` 進入應用
  - [ ] 測試完整對話流程：
    - [ ] 輸入「你好」並送出
    - [ ] 驗證 LLM 回應即時顯示
    - [ ] 驗證回應完成後自動播放語音
    - [ ] 驗證語音清晰、發音正確
    - [ ] 驗證播放延遲 < 1.5 秒
  - [ ] 測試播放控制：
    - [ ] 播放中點擊「暫停」→ 語音暫停
    - [ ] 點擊「繼續」→ 語音從暫停位置繼續
    - [ ] 點擊「停止」→ 語音停止，控制面板消失
  - [ ] 測試多輪對話：
    - [ ] 連續輸入 3 則訊息
    - [ ] 驗證每則回應都自動播放語音
    - [ ] 驗證前一則語音播放完畢再播放下一則
  - [ ] 測試錯誤處理：
    - [ ] 停止 TTS API，測試 TTS 失敗情境
    - [ ] 驗證錯誤訊息顯示但不中斷對話
  - [ ] 使用 React DevTools 檢查 audioStore 狀態正確更新
  - [ ] 驗證 Console 無錯誤或警告訊息
  - [ ] 執行 TypeScript 型別檢查（`pnpm run type-check`）

---

## Dev Notes

### 相關來源樹（Source Tree）

根據架構文件，本 Story 涉及的檔案結構：

```
avatar-chat-poc/
├── lib/
│   └── utils/
│       └── audio.ts               # Web Audio API 播放管理器 (本 Story)
├── stores/
│   ├── chatStore.ts               # 整合自動 TTS 播放 (重構)
│   └── audioStore.ts              # 整合 TTS API 與播放邏輯 (重構)
├── components/
│   └── chat/
│       └── AudioControls.tsx      # 音訊控制 UI 組件 (本 Story)
├── app/
│   └── page.tsx                   # 整合 AudioControls 組件 (重構)
└── types/
    └── audio.ts                   # Audio 相關型別定義
```

### 技術實作細節

**Web Audio API 基本概念**：
```typescript
// 1. 建立 AudioContext（音訊處理環境）
const audioContext = new AudioContext();

// 2. 載入音訊檔案並解碼
const arrayBuffer = await response.arrayBuffer();
const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

// 3. 建立音訊源節點
const source = audioContext.createBufferSource();
source.buffer = audioBuffer;
source.connect(audioContext.destination); // 連接到輸出（喇叭）

// 4. 播放音訊
source.start(0); // 從 0 秒開始播放
```

**為何使用 AudioContext 而非 `<audio>` 標籤？**
- ✅ **精確控制**: 可控制播放位置、速度、音量
- ✅ **音訊處理**: 可加入濾波器、效果器、分析器
- ✅ **Lip Sync**: 可精確取得播放時間，用於嘴型同步（Story 4.3）
- ✅ **效能**: 低延遲，適合即時應用
- ❌ **複雜度**: 比 `<audio>` 標籤複雜（可接受）

**暫停/恢復實作原理**：
```typescript
// AudioBufferSourceNode 不支援 pause()，需要自行實作

// 暫停: 記錄當前播放位置
pause() {
  this.pauseTime = audioContext.currentTime - this.startTime;
  source.stop(); // 停止播放
  this.isPaused = true;
}

// 恢復: 從暫停位置重新播放
resume() {
  const source = audioContext.createBufferSource();
  source.buffer = this.currentBuffer;
  source.connect(audioContext.destination);
  source.start(0, this.pauseTime); // 從暫停位置開始
  this.startTime = audioContext.currentTime - this.pauseTime;
}
```

**Blob URL 管理**：
```typescript
// 建立 Blob URL（臨時 URL）
const audioUrl = URL.createObjectURL(audioBlob);

// 使用完畢後釋放記憶體
URL.revokeObjectURL(audioUrl);

// 為何使用 Blob URL？
// ✅ 無需上傳到伺服器（節省時間與成本）
// ✅ 可直接播放二進位音訊資料
// ✅ 自動快取（瀏覽器層級）
```

**單例模式 AudioPlayer**：
```typescript
// 為何使用單例模式？
// ✅ 避免多個 AudioContext 實例（瀏覽器限制 6 個）
// ✅ 確保同時只有一個音訊播放
// ✅ 簡化狀態管理

let globalAudioPlayer: AudioPlayer | null = null;

export function getAudioPlayer(): AudioPlayer {
  if (!globalAudioPlayer) {
    globalAudioPlayer = new AudioPlayer();
  }
  return globalAudioPlayer;
}
```

### 重要架構決策

1. **為何建立獨立 AudioPlayer 類別？**
   - ✅ **關注點分離**: 播放邏輯獨立於 Store
   - ✅ **可重複使用**: 可在其他地方使用（如背景音樂）
   - ✅ **可測試性**: 獨立類別易於單元測試
   - ✅ **封裝**: 隱藏 Web Audio API 複雜性

2. **為何在 audioStore 而非 chatStore 中處理播放？**
   - ✅ **職責明確**: chatStore 處理對話，audioStore 處理音訊
   - ✅ **可擴展性**: 未來可加入背景音樂、音效等
   - ✅ **狀態隔離**: 音訊狀態獨立，不影響對話狀態
   - ✅ **可重複使用**: 其他功能也可使用 audioStore

3. **為何自動播放而非手動點擊？**
   - ✅ **使用者體驗**: 對話流程更自然流暢
   - ✅ **擬人化**: 模擬真人對話（說完話自動說出聲）
   - ✅ **減少操作**: 使用者無需額外點擊
   - ⚠️ **瀏覽器限制**: 部分瀏覽器需使用者互動才能播放（已透過對話輸入觸發）

4. **為何加入播放控制 UI？**
   - ✅ **使用者控制**: 讓使用者可暫停、停止語音
   - ✅ **視覺反饋**: 明確顯示播放狀態
   - ✅ **除錯方便**: 開發階段可手動控制播放
   - ✅ **無障礙**: 提供鍵盤控制選項（未來）

5. **為何實作音訊佇列？**
   - ✅ **連續對話**: 支援快速連續提問
   - ✅ **順序播放**: 確保語音按順序播放，不重疊
   - ✅ **使用者體驗**: 避免語音被打斷或跳過
   - ✅ **可擴展性**: 未來可加入優先權佇列

### Testing

**測試框架**: 手動測試 + React DevTools + Chrome DevTools（POC 階段）

**測試範圍**:
1. ✅ Web Audio API 播放函式正常運作
2. ✅ TTS API 呼叫與音訊載入成功
3. ✅ 自動播放功能正常（LLM 回應後觸發）
4. ✅ 播放延遲 < 1.5 秒
5. ✅ 語音清晰、發音正確
6. ✅ 播放控制（暫停、繼續、停止）正常
7. ✅ audioStore 狀態正確更新
8. ✅ 音訊佇列功能正常（連續對話）
9. ✅ 錯誤處理正確（TTS 失敗不中斷對話）
10. ✅ 無記憶體洩漏（長時間使用）

**測試執行方式**:
```bash
# 1. 啟動開發伺服器
pnpm dev

# 2. 開啟應用
http://localhost:3000

# 3. 測試自動播放
- 輸入「你好」並送出
- 等待 LLM 回應完成
- 觀察語音自動播放（應聽到聲音）
- 觀察音訊控制面板出現（左下角）

# 4. 測試播放控制
- 播放中點擊「暫停」按鈕
- 驗證語音暫停
- 點擊「繼續」按鈕
- 驗證語音從暫停位置繼續
- 點擊「停止」按鈕
- 驗證語音停止，控制面板消失

# 5. 測試連續對話
- 快速連續輸入 3 則訊息
- 驗證每則回應都自動播放
- 驗證語音不重疊（佇列順序播放）

# 6. 測試錯誤處理
- 關閉 TTS API（或設定錯誤的 API Key）
- 輸入訊息並送出
- 驗證對話正常顯示但無語音
- 驗證 Console 顯示錯誤但不崩潰

# 7. 測試效能
- 開啟 Chrome DevTools > Performance
- 記錄對話流程
- 驗證播放延遲 < 1.5 秒
- 驗證無明顯記憶體增長
```

**驗證清單**:
- [ ] `pnpm dev` 啟動無錯誤
- [ ] LLM 回應完成後自動播放語音
- [ ] 語音清晰、發音正確（繁體中文）
- [ ] 播放延遲 < 1.5 秒（LLM 完成到語音開始）
- [ ] 音訊控制面板正確顯示（左下角浮動）
- [ ] 暫停按鈕正常運作（語音暫停）
- [ ] 繼續按鈕正常運作（從暫停位置繼續）
- [ ] 停止按鈕正常運作（語音停止，面板消失）
- [ ] 連續對話時語音順序播放，不重疊
- [ ] TTS 失敗時對話不中斷（僅無語音）
- [ ] audioStore 狀態正確更新（IDLE, LOADING, PLAYING, PAUSED）
- [ ] React DevTools 顯示正確 state
- [ ] Console 無錯誤或警告（正常流程）
- [ ] TypeScript 型別檢查通過

### 效能考量

**播放延遲分析**:
```
使用者送出訊息
  ↓
LLM 回應開始 (~1s)
  ↓
LLM 回應完成 (~3s)
  ↓
TTS API 呼叫 (~0.5s)
  ↓
TTS 轉換 (~1-2s)
  ↓
音訊下載 (~0.2s)
  ↓
AudioBuffer 解碼 (~0.1s)
  ↓
播放開始
---
總延遲: ~5-7s（端到端）
LLM 完成到播放: ~1.5-2.5s（符合 AC）
```

**記憶體管理**:
- **Blob URL**: 使用後立即釋放（`URL.revokeObjectURL`）
- **AudioBuffer**: 播放完畢後由 GC 自動回收
- **AudioContext**: 單例模式，整個應用共用一個實例

**未來優化方向**（MVP 階段）:
1. **Streaming TTS**: 使用 Azure Speech 串流 API（即時播放）
2. **Audio Preloading**: 預先載入下一則音訊（減少等待）
3. **Compression**: 使用更低位元率（如 16kbps → 12kbps）
4. **Caching**: 快取常見回應音訊（節省 API 呼叫）

### 安全性考量

**Web Audio API 安全**:
- ✅ Web Audio API 在瀏覽器沙箱中運行，無安全風險
- ✅ 音訊檔案透過 HTTPS 傳輸（生產環境）
- ⚠️ Blob URL 僅在當前頁面有效（無法外部存取）

**自動播放政策**:
- ✅ 現代瀏覽器限制自動播放（需使用者互動）
- ✅ 本應用透過對話輸入觸發播放（符合政策）
- ⚠️ 若使用者未互動過，可能無法自動播放（需處理）

**錯誤處理安全**:
- ✅ TTS 失敗不影響對話流程（降級方案）
- ✅ 錯誤訊息不洩漏敏感資訊
- ✅ 使用者仍可繼續對話（僅無語音）

### 依賴關係

**前置條件**:
- ✅ Story 3.2 已完成（audioStore 已建立）
- ✅ Story 3.4 已完成（對話流程已完成）
- ✅ Story 3.5 已完成（TTS API 已實作）
- ✅ Node.js 18+ 與 pnpm 已安裝

**後續 Story 依賴**:
- **Story 3.7**: 會整合完整端到端流程（對話 → TTS → 播放 → Lip Sync）
- **Story 4.3**: 會使用 audioStore 的播放時間資訊同步 Lip Sync

**關鍵路徑**:
- 本 Story 完成後，使用者可完整體驗語音對話
- Story 3.7 整合所有 Epic 3 功能，驗證端到端體驗
- Story 4.x（Lip Sync）依賴本 Story 的音訊播放時間資訊

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-14 | 1.0 | 建立 Story 3.6 草稿 | SM Agent |

---

## Dev Agent Record

*(此部分由 Dev Agent 在實作時填寫)*

### Agent Model Used
_待填寫_

### Debug Log References
_待填寫_

### Completion Notes List
_待填寫_

### File List
_待填寫_

---

## QA Results

*(此部分由 QA Agent 在審核時填寫)*

_待填寫_
