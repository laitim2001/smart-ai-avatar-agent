# Story 3.3: Chat API 實作（Azure OpenAI + SSE 串流）

## Status
Approved

---

## Story

**As a** 開發者,
**I want** 建立 Chat API，整合 Azure OpenAI 並使用 SSE 串流回應,
**so that** 使用者可以即時看到 LLM 的回應文字。

---

## Acceptance Criteria

1. 建立 `app/api/chat/route.ts` Chat API 路由
2. 接收 POST 請求，body 包含 `messages: Message[]`（對話歷史）
3. 呼叫 Azure OpenAI Chat Completions API（GPT-4 Turbo），啟用 `stream: true`
4. 使用 Server-Sent Events (SSE) 格式串流回應：每個 chunk 格式 `data: {"content": "文字"}\n\n`
5. 錯誤處理：API 失敗返回 500，包含錯誤訊息 JSON
6. 超時設定：10 秒無回應自動中斷連線
7. 使用 Postman 或 curl 測試 API，收到串流回應
8. 環境變數驗證：缺少 API Key 時返回適當錯誤訊息

---

## Tasks / Subtasks

- [ ] **Task 1: 建立 Azure OpenAI Client 初始化函式** (AC: 3)
  - [ ] 開啟或建立 `lib/azure/openai.ts` 檔案
  - [ ] 實作 Azure OpenAI 客戶端初始化：
    ```typescript
    import { AzureOpenAI } from '@azure/openai';

    /**
     * 建立 Azure OpenAI 客戶端
     * 使用環境變數配置 API Key 與 Endpoint
     */
    export function createOpenAIClient() {
      const apiKey = process.env.AZURE_OPENAI_API_KEY;
      const endpoint = process.env.AZURE_OPENAI_ENDPOINT;

      if (!apiKey || !endpoint) {
        throw new Error(
          'Missing Azure OpenAI credentials. Please set AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT in environment variables.'
        );
      }

      return new AzureOpenAI({
        apiKey,
        endpoint,
        apiVersion: '2024-02-15-preview' // GPT-4 Turbo 支援版本
      });
    }

    /**
     * 取得 GPT-4 Turbo 部署名稱
     */
    export function getDeploymentName() {
      return process.env.AZURE_OPENAI_DEPLOYMENT || 'gpt-4-turbo';
    }
    ```
  - [ ] 加入 JSDoc 註解說明函式用途
  - [ ] 加入錯誤處理（缺少環境變數時拋出錯誤）
  - [ ] 驗證函式可正確建立客戶端

- [ ] **Task 2: 定義 Chat API 型別** (AC: 2)
  - [ ] 開啟或建立 `types/chat.ts` 檔案
  - [ ] 定義 Chat Request 型別：
    ```typescript
    export interface ChatMessage {
      role: 'user' | 'assistant' | 'system';
      content: string;
    }

    export interface ChatRequest {
      messages: ChatMessage[];
      temperature?: number;      // 可選，預設 0.7
      max_tokens?: number;       // 可選，預設 800
    }
    ```
  - [ ] 定義 SSE Chunk 型別：
    ```typescript
    export interface SSEChunk {
      content: string;           // 本次 chunk 的文字內容
      done?: boolean;            // 是否為最後一個 chunk
    }
    ```
  - [ ] 定義 Error Response 型別：
    ```typescript
    export interface ErrorResponse {
      error: string;             // 錯誤訊息
      code?: string;             // 錯誤代碼（如 'TIMEOUT', 'API_ERROR'）
      timestamp: string;         // 錯誤發生時間（ISO 格式）
    }
    ```
  - [ ] 加入 JSDoc 註解說明每個型別用途
  - [ ] 驗證型別定義完整且正確

- [ ] **Task 3: 實作 Chat API 路由基本結構** (AC: 1, 2)
  - [ ] 建立目錄 `app/api/chat/`（如尚未存在）
  - [ ] 建立 `app/api/chat/route.ts` 檔案
  - [ ] 實作基本路由結構：
    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { createOpenAIClient, getDeploymentName } from '@/lib/azure/openai';
    import { ChatRequest, ErrorResponse } from '@/types/chat';

    export const runtime = 'edge'; // 使用 Edge Runtime 提升效能

    /**
     * Chat API - 處理 LLM 對話並使用 SSE 串流回應
     */
    export async function POST(request: NextRequest) {
      try {
        // 解析請求 body
        const body: ChatRequest = await request.json();

        // 驗證必要欄位
        if (!body.messages || body.messages.length === 0) {
          return NextResponse.json(
            {
              error: 'Missing required field: messages',
              code: 'INVALID_REQUEST',
              timestamp: new Date().toISOString()
            } as ErrorResponse,
            { status: 400 }
          );
        }

        // 後續 Task 將實作 SSE 串流邏輯
        return new NextResponse('SSE stream to be implemented', {
          status: 200,
          headers: {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive'
          }
        });

      } catch (error) {
        console.error('[Chat API Error]', error);

        return NextResponse.json(
          {
            error: error instanceof Error ? error.message : 'Internal server error',
            code: 'API_ERROR',
            timestamp: new Date().toISOString()
          } as ErrorResponse,
          { status: 500 }
        );
      }
    }
    ```
  - [ ] 加入 JSDoc 註解說明 API 用途
  - [ ] 設定 Edge Runtime（提升效能與 SSE 支援）
  - [ ] 實作基本請求驗證（messages 欄位檢查）
  - [ ] 實作基本錯誤處理
  - [ ] 驗證 API 路由建立成功

- [ ] **Task 4: 實作 Azure OpenAI 串流呼叫邏輯** (AC: 3)
  - [ ] 在 `route.ts` 中實作 Azure OpenAI 串流呼叫：
    ```typescript
    // 建立 OpenAI 客戶端
    const client = createOpenAIClient();
    const deploymentName = getDeploymentName();

    // 呼叫 Chat Completions API（啟用串流）
    const response = await client.chat.completions.create({
      model: deploymentName,
      messages: body.messages,
      temperature: body.temperature ?? 0.7,
      max_tokens: body.max_tokens ?? 800,
      stream: true  // 啟用 SSE 串流
    });
    ```
  - [ ] 加入超時控制邏輯（10 秒）：
    ```typescript
    const TIMEOUT_MS = 10000; // 10 秒

    const timeoutController = new AbortController();
    const timeoutId = setTimeout(() => {
      timeoutController.abort();
    }, TIMEOUT_MS);
    ```
  - [ ] 整合超時控制到 API 呼叫（如 Azure SDK 支援）
  - [ ] 測試超時邏輯（模擬慢速回應）
  - [ ] 驗證串流回應正確建立

- [ ] **Task 5: 實作 SSE 串流回應格式化** (AC: 4)
  - [ ] 實作 SSE 串流處理邏輯：
    ```typescript
    // 建立 SSE 回應串流
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of response) {
            const content = chunk.choices[0]?.delta?.content || '';

            if (content) {
              // 格式化為 SSE 格式：data: {"content": "..."}\n\n
              const sseChunk = `data: ${JSON.stringify({ content })}\n\n`;
              controller.enqueue(encoder.encode(sseChunk));
            }
          }

          // 串流結束，發送 done 訊號
          const doneChunk = `data: ${JSON.stringify({ content: '', done: true })}\n\n`;
          controller.enqueue(encoder.encode(doneChunk));

          controller.close();
          clearTimeout(timeoutId);

        } catch (error) {
          console.error('[SSE Stream Error]', error);

          // 發送錯誤訊息給客戶端
          const errorChunk = `data: ${JSON.stringify({
            error: 'Stream interrupted',
            code: 'STREAM_ERROR'
          })}\n\n`;
          controller.enqueue(encoder.encode(errorChunk));
          controller.close();
          clearTimeout(timeoutId);
        }
      }
    });

    return new NextResponse(stream, {
      status: 200,
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    });
    ```
  - [ ] 實作 SSE 格式化（`data: {...}\n\n`）
  - [ ] 實作串流結束訊號（`done: true`）
  - [ ] 實作串流錯誤處理
  - [ ] 驗證 SSE 格式正確

- [ ] **Task 6: 實作環境變數驗證與錯誤處理** (AC: 5, 6, 8)
  - [ ] 在 `createOpenAIClient` 中加入環境變數驗證（已在 Task 1 實作）
  - [ ] 實作 API 錯誤分類與處理：
    ```typescript
    catch (error) {
      console.error('[Chat API Error]', error);

      // 分類錯誤類型
      let errorCode = 'API_ERROR';
      let errorMessage = 'Internal server error';
      let statusCode = 500;

      if (error instanceof Error) {
        errorMessage = error.message;

        // Azure OpenAI API 錯誤
        if (error.message.includes('quota')) {
          errorCode = 'QUOTA_EXCEEDED';
          errorMessage = 'API quota exceeded. Please try again later.';
        } else if (error.message.includes('credentials')) {
          errorCode = 'INVALID_CREDENTIALS';
          errorMessage = 'Invalid Azure OpenAI credentials.';
          statusCode = 401;
        } else if (error.name === 'AbortError') {
          errorCode = 'TIMEOUT';
          errorMessage = 'Request timeout (10 seconds exceeded).';
          statusCode = 408;
        }
      }

      return NextResponse.json(
        {
          error: errorMessage,
          code: errorCode,
          timestamp: new Date().toISOString()
        } as ErrorResponse,
        { status: statusCode }
      );
    }
    ```
  - [ ] 加入詳細錯誤日誌（console.error）
  - [ ] 測試各種錯誤情境（缺少環境變數、API 失敗、超時）
  - [ ] 驗證錯誤回應格式正確

- [ ] **Task 7: 加入 System Prompt 與對話參數優化** (AC: 3)
  - [ ] 定義 Avatar 的 System Prompt：
    ```typescript
    const AVATAR_SYSTEM_PROMPT = `你是一個友善、專業的 AI 虛擬助手。
    你的回答應該：
    1. 簡潔明瞭（每次回答 2-3 句話，約 50-100 字）
    2. 使用繁體中文
    3. 語氣友善、自然，像真人對話
    4. 避免過於正式或機械化的回答
    5. 必要時可以使用表情符號增加親切感

    請記住：你正在透過 3D Avatar 與使用者對話，保持對話的自然流暢性。`;

    // 在 API 呼叫前插入 System Prompt
    const messagesWithSystem = [
      { role: 'system', content: AVATAR_SYSTEM_PROMPT },
      ...body.messages
    ];
    ```
  - [ ] 優化對話參數：
    ```typescript
    const response = await client.chat.completions.create({
      model: deploymentName,
      messages: messagesWithSystem,
      temperature: 0.7,      // 平衡創意與一致性
      max_tokens: 800,       // 限制回應長度（約 200 中文字）
      top_p: 0.95,           // Nucleus sampling
      frequency_penalty: 0.3, // 減少重複
      presence_penalty: 0.3,  // 鼓勵新主題
      stream: true
    });
    ```
  - [ ] 加入 System Prompt 說明註解
  - [ ] 測試不同參數組合，找出最佳對話品質
  - [ ] 驗證 System Prompt 正確影響 LLM 回應風格

- [ ] **Task 8: API 測試與驗證** (AC: 7)
  - [ ] 建立測試腳本 `test-chat-api.sh`（開發用）：
    ```bash
    #!/bin/bash
    # 測試 Chat API 使用 curl

    curl -N -X POST http://localhost:3000/api/chat \
      -H "Content-Type: application/json" \
      -d '{
        "messages": [
          {"role": "user", "content": "你好，請介紹一下你自己"}
        ]
      }'
    ```
  - [ ] 使用 Postman 建立 Chat API 測試集合：
    - [ ] 測試 1: 正常對話（單輪）
    - [ ] 測試 2: 多輪對話（包含對話歷史）
    - [ ] 測試 3: 缺少 messages 欄位（預期 400 錯誤）
    - [ ] 測試 4: 空 messages 陣列（預期 400 錯誤）
    - [ ] 測試 5: 超時測試（如可模擬）
  - [ ] 執行 `pnpm dev` 啟動開發伺服器
  - [ ] 使用 curl 測試 API，驗證 SSE 串流回應
  - [ ] 使用 Postman 測試所有測試案例
  - [ ] 驗證回應格式正確：
    - [ ] SSE 格式：`data: {"content": "..."}\n\n`
    - [ ] 最後 chunk 包含 `done: true`
    - [ ] 錯誤回應為 JSON 格式
  - [ ] 記錄測試結果於 Dev Agent Record

- [ ] **Task 9: 整合測試與文件** (AC: 1-8)
  - [ ] 建立 `docs/api/chat.md` API 文件：
    ```markdown
    # Chat API 文件

    ## Endpoint
    `POST /api/chat`

    ## Request Body
    \```json
    {
      "messages": [
        {"role": "user", "content": "你好"}
      ],
      "temperature": 0.7,  // 可選
      "max_tokens": 800    // 可選
    }
    \```

    ## Response (SSE Stream)
    \```
    data: {"content": "你好"}

    data: {"content": "！我是"}

    data: {"content": " AI 助手"}

    data: {"content": "", "done": true}
    \```

    ## Error Response
    \```json
    {
      "error": "Missing required field: messages",
      "code": "INVALID_REQUEST",
      "timestamp": "2025-10-14T10:30:00.000Z"
    }
    \```

    ## 狀態碼
    - `200`: 成功（SSE 串流）
    - `400`: 請求參數錯誤
    - `401`: 認證失敗
    - `408`: 請求超時
    - `500`: 伺服器錯誤
    ```
  - [ ] 更新專案 README.md，加入 Chat API 使用說明
  - [ ] 執行完整測試流程，確保所有 AC 達成
  - [ ] 驗證 Console 無錯誤或警告訊息
  - [ ] 執行 TypeScript 型別檢查（`pnpm run type-check`）

---

## Dev Notes

### 相關來源樹（Source Tree）

根據架構文件，本 Story 涉及的檔案結構：

```
avatar-chat-poc/
├── app/
│   └── api/
│       └── chat/
│           └── route.ts        # Chat API 路由 (本 Story)
├── lib/
│   └── azure/
│       └── openai.ts           # Azure OpenAI 客戶端初始化 (本 Story)
├── types/
│   └── chat.ts                 # Chat 相關型別定義 (擴充)
├── docs/
│   └── api/
│       └── chat.md             # Chat API 文件 (本 Story)
├── .env.local                  # 環境變數（開發用）
└── test-chat-api.sh            # 測試腳本（開發用）
```

### 技術實作細節

**Server-Sent Events (SSE) 概念**：
- **單向通訊**: 伺服器 → 客戶端（適合串流回應）
- **HTTP 協議**: 基於標準 HTTP，無需 WebSocket
- **格式規範**: `data: <JSON>\n\n`（每個訊息以兩個換行符結束）
- **自動重連**: 瀏覽器 EventSource API 支援自動重連

**為何使用 SSE 而非 WebSocket？**
- ✅ **簡單**: 基於 HTTP，無需握手協議
- ✅ **單向足夠**: LLM 回應不需客戶端 → 伺服器通訊
- ✅ **瀏覽器支援**: 原生 EventSource API
- ✅ **Azure 支援**: Next.js Edge Runtime 原生支援 SSE

**Azure OpenAI Chat Completions API 串流格式**：
```typescript
// 啟用串流
const response = await client.chat.completions.create({
  stream: true,  // 關鍵參數
  // ... 其他參數
});

// 迭代串流 chunks
for await (const chunk of response) {
  const content = chunk.choices[0]?.delta?.content || '';
  // content: "你", "好", "！", "我", "是", ...
}
```

**SSE 格式化邏輯**：
```typescript
// 原始 chunk: { content: "你好" }
// SSE 格式化:
const sseChunk = `data: ${JSON.stringify({ content: "你好" })}\n\n`;
// 輸出: "data: {\"content\":\"你好\"}\n\n"

// 客戶端接收後解析:
const data = JSON.parse(event.data); // { content: "你好" }
```

**Edge Runtime vs Node.js Runtime**:
```typescript
export const runtime = 'edge'; // 使用 Edge Runtime

// 優勢:
// ✅ 啟動速度快（冷啟動 < 50ms）
// ✅ 記憶體使用低
// ✅ 原生支援 SSE 串流
// ✅ 全域分散式部署（Azure Static Web Apps）

// 限制:
// ❌ 不支援 Node.js 特定 API（如 fs, child_process）
// ❌ 執行時間限制（通常 30-60 秒，足夠 LLM 回應）
```

**超時控制實作**：
```typescript
const TIMEOUT_MS = 10000;
const timeoutController = new AbortController();

const timeoutId = setTimeout(() => {
  timeoutController.abort(); // 中斷請求
}, TIMEOUT_MS);

// 清理 timeout（成功或失敗後）
clearTimeout(timeoutId);
```

**錯誤分類策略**：
```typescript
// 1. 請求驗證錯誤 (400)
if (!body.messages) → INVALID_REQUEST

// 2. 認證錯誤 (401)
if (missing API key) → INVALID_CREDENTIALS

// 3. 超時錯誤 (408)
if (timeout exceeded) → TIMEOUT

// 4. Azure API 錯誤 (500)
if (quota exceeded) → QUOTA_EXCEEDED
if (model not found) → MODEL_ERROR

// 5. 未知錯誤 (500)
else → API_ERROR
```

### 重要架構決策

1. **為何使用 Edge Runtime？**
   - ✅ **效能優勢**: 冷啟動快，適合 Serverless 環境
   - ✅ **SSE 支援**: Next.js Edge Runtime 原生支援 SSE
   - ✅ **成本效益**: Azure Static Web Apps 的 Edge Functions 成本低
   - ✅ **全域分散**: 自動部署至多個 Azure 節點，降低延遲

2. **為何加入 System Prompt？**
   - ✅ **風格控制**: 確保 Avatar 回應風格一致（友善、簡潔）
   - ✅ **長度限制**: 引導 LLM 產生簡短回應（適合語音播放）
   - ✅ **繁中優化**: 明確指定使用繁體中文
   - ✅ **角色設定**: 建立「AI 虛擬助手」人設

3. **為何設定 max_tokens: 800？**
   - ✅ **成本控制**: 限制單次回應長度，降低 API 成本
   - ✅ **TTS 適配**: 約 200 中文字，語音播放時間 ~20-30 秒（合理）
   - ✅ **使用者體驗**: 避免過長回應造成等待（POC 階段）

4. **為何需要超時控制？**
   - ✅ **使用者體驗**: 10 秒無回應會讓使用者焦慮
   - ✅ **資源釋放**: 避免長時間佔用 Edge Function 資源
   - ✅ **錯誤處理**: 超時時返回明確錯誤訊息，而非無限等待

5. **為何發送 `done: true` 訊號？**
   - ✅ **客戶端判斷**: 明確告知客戶端串流已結束
   - ✅ **狀態管理**: 客戶端可據此更新 `isLoading: false`
   - ✅ **後續處理**: 觸發 TTS 呼叫（Story 3.5）

### Testing

**測試框架**: 手動測試 + Postman + curl（POC 階段）

**測試範圍**:
1. ✅ API 路由建立成功，回應正確 HTTP 狀態碼
2. ✅ 正常對話流程（單輪、多輪）SSE 串流正常
3. ✅ SSE 格式正確（`data: {...}\n\n`）
4. ✅ `done: true` 訊號正確發送
5. ✅ 請求驗證正確（缺少 messages 返回 400）
6. ✅ 環境變數驗證正確（缺少 API Key 返回錯誤）
7. ✅ 超時控制正常（10 秒超時返回 408）
8. ✅ 錯誤分類正確（不同錯誤返回不同 code）
9. ✅ System Prompt 正確影響回應風格

**測試執行方式**:
```bash
# 1. 啟動開發伺服器
pnpm dev

# 2. 測試正常對話（curl）
curl -N -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"你好"}]}'

# 預期輸出（SSE 串流）:
# data: {"content":"你好"}
#
# data: {"content":"！我是"}
#
# data: {"content":" AI 助手"}
#
# data: {"content":"","done":true}

# 3. 測試錯誤處理（缺少 messages）
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{}'

# 預期輸出（JSON）:
# {"error":"Missing required field: messages","code":"INVALID_REQUEST","timestamp":"..."}

# 4. 使用 Postman 測試完整測試集合
```

**驗證清單**:
- [ ] `pnpm dev` 啟動無錯誤
- [ ] POST `/api/chat` 返回 SSE 串流
- [ ] SSE 格式正確（可使用線上 SSE 工具驗證）
- [ ] 多輪對話正確保留上下文
- [ ] 缺少 messages 返回 400 錯誤
- [ ] 缺少環境變數時啟動失敗並有明確錯誤訊息
- [ ] 超時測試返回 408 錯誤（如可模擬）
- [ ] System Prompt 影響回應風格（簡潔、繁中、友善）
- [ ] Console 日誌顯示詳細錯誤資訊（開發模式）
- [ ] TypeScript 型別檢查通過

**Postman 測試集合範例**:
```json
{
  "info": {
    "name": "Chat API Tests",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "正常對話（單輪）",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/chat",
        "header": [{"key": "Content-Type", "value": "application/json"}],
        "body": {
          "mode": "raw",
          "raw": "{\"messages\":[{\"role\":\"user\",\"content\":\"你好，請介紹一下你自己\"}]}"
        }
      }
    },
    {
      "name": "多輪對話（包含歷史）",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/chat",
        "body": {
          "mode": "raw",
          "raw": "{\"messages\":[{\"role\":\"user\",\"content\":\"我叫小明\"},{\"role\":\"assistant\",\"content\":\"你好小明！\"},{\"role\":\"user\",\"content\":\"你還記得我的名字嗎？\"}]}"
        }
      }
    },
    {
      "name": "缺少 messages 欄位（預期 400）",
      "request": {
        "method": "POST",
        "url": "http://localhost:3000/api/chat",
        "body": {
          "mode": "raw",
          "raw": "{}"
        }
      }
    }
  ]
}
```

### 效能考量

**SSE 串流效能**:
- **首字延遲**: Azure OpenAI GPT-4 Turbo 通常 < 1 秒
- **完整回應**: 200 字回應約 3-5 秒（取決於 API 負載）
- **網路開銷**: SSE over HTTP/1.1，每個 chunk 約 50-100 bytes

**Edge Runtime 效能**:
- **冷啟動**: < 50ms（比 Node.js Runtime 快 10-20 倍）
- **並發**: Edge Functions 可自動擴展，無需配置
- **記憶體**: 每個請求約 10-20 MB（遠低於 Node.js Runtime）

**成本優化**:
- **max_tokens 限制**: 800 tokens 約 $0.008/次（GPT-4 Turbo 定價）
- **SSE 連線時間**: 平均 5 秒，Edge Function 成本可忽略
- **快取策略**: 未來可實作常見問題快取（降低 API 呼叫）

**未來優化方向**（MVP 階段）:
1. **Response Caching**: 快取常見問題回應（如「你好」「介紹自己」）
2. **Streaming Chunking**: 優化 chunk 大小（目前每個 token 一個 chunk，可合併）
3. **Parallel Requests**: 支援同時多個對話（目前單一串流）
4. **Rate Limiting**: 加入請求頻率限制（避免濫用）

### 安全性考量

**API Key 安全**:
- ✅ 所有 Azure API Key 透過環境變數管理
- ✅ 環境變數不提交到 Git（`.env.local` 在 `.gitignore`）
- ✅ Azure Portal 配置生產環境變數（隔離）
- ⚠️ POC 階段無需用戶認證（公開存取）

**輸入驗證**:
- ✅ 驗證 messages 欄位存在且為陣列
- ✅ 驗證 messages 長度 > 0
- ⚠️ 未驗證 messages 內容長度（未來可加入，如單則 < 1000 字）
- ⚠️ 未驗證 messages 角色（user/assistant/system）

**錯誤訊息安全**:
- ✅ 錯誤訊息不洩漏敏感資訊（如 API Key）
- ✅ 使用通用錯誤訊息（「Internal server error」）
- ✅ 詳細錯誤僅記錄於 console（不返回客戶端）

**未來考量**（MVP 階段）:
- 加入請求頻率限制（Rate Limiting）
- 加入 CORS 設定（限制允許的來源）
- 加入請求大小限制（防止 DoS 攻擊）
- 加入內容過濾（避免不當對話）

### 依賴關係

**前置條件**:
- ✅ Story 1.1 已完成（Next.js 專案已建立）
- ✅ Story 1.2 已完成（Azure OpenAI 服務已註冊）
- ✅ Story 3.2 已完成（chatStore 已建立，提供型別定義）
- ✅ 環境變數已配置（`AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`）
- ✅ Node.js 18+ 與 pnpm 已安裝

**後續 Story 依賴**:
- **Story 3.4**: 會在前端使用本 API，實作 SSE 串流接收與顯示
- **Story 3.5**: 會使用本 API 回應的文字內容呼叫 TTS API
- **Story 3.7**: 會整合完整對話流程（本 API → SSE 顯示 → TTS → 播放）

**關鍵路徑**:
- 本 Story 是 Epic 3 的核心後端 API，必須優先完成
- Story 3.4（前端 SSE 接收）直接依賴本 API
- Story 3.5（TTS API）與本 API 並行開發，無阻塞依賴

**與 Azure 服務整合**:
- **Azure OpenAI Service**: 必須已建立資源並部署 GPT-4 Turbo 模型
- **Azure Static Web Apps**: 環境變數需在 Azure Portal 配置
- **Edge Runtime**: 確保 Next.js 13.4+ 支援（已滿足）

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-14 | 1.0 | 建立 Story 3.3 草稿 | SM Agent |

---

## Dev Agent Record

*(此部分由 Dev Agent 在實作時填寫)*

### Agent Model Used
_待填寫_

### Debug Log References
_待填寫_

### Completion Notes List
_待填寫_

### File List
_待填寫_

---

## QA Results

*(此部分由 QA Agent 在審核時填寫)*

_待填寫_
